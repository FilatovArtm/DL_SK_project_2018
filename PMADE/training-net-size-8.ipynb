{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "from loader import get_train_loader\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from networks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder_people_4 = torch.load('autoencoder.people.4.pt')\n",
    "autoencoder_stickmans_4 = torch.load('autoencoder.stickmen.4.pt')\n",
    "autoencoder_people_8 = torch.load('autoencoder.people.8.pt')\n",
    "autoencoder_stickmans_8 = torch.load('autoencoder.stickmen.8.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "mask4_group_1 = np.zeros((batch_size, 3, 8, 8)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(8):\n",
    "            for j in range(8):\n",
    "                if i % 2 == 0 and j % 2 == 0:\n",
    "                    mask4_group_1[m][n][i][j] = True\n",
    "\n",
    "mask4_group_2 = np.zeros((batch_size, 3, 8, 8)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(8):\n",
    "            for j in range(8):\n",
    "                if i % 2 == 0 and j % 2 == 1:\n",
    "                    mask4_group_2[m][n][i][j] = True\n",
    "\n",
    "mask4_group_3 = np.zeros((batch_size, 3, 8, 8)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(8):\n",
    "            for j in range(8):\n",
    "                if i % 2 == 1 and j % 2 == 0:\n",
    "                    mask4_group_3[m][n][i][j] = True\n",
    "\n",
    "mask4_group_4 = np.zeros((batch_size, 3, 8, 8)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(8):\n",
    "            for j in range(8):\n",
    "                if i % 2 == 1 and j % 2 == 1:\n",
    "                    mask4_group_4[m][n][i][j] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net4_group2 = torch.load(\"net4.group2.pt\")\n",
    "net4_group3 = torch.load(\"net4.group3.pt\")\n",
    "net4_group4 = torch.load(\"net4.group4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_input_into_image_4(X_batch_input_initial, y_batch_output, is_plot=False):\n",
    "    X_batch_input = X_batch_input_initial.clone()\n",
    "    X_batch_input = X_batch_input[mask4_group_1.nonzero()].view((batch_size, 3, 4, 4))\n",
    "    X_batch_input = Variable(X_batch_input).cuda()\n",
    "    \n",
    "    group_1 = X_batch_input.clone()\n",
    "    group_2 = net4_group2(X_batch_input,\n",
    "                 keypoints=autoencoder_stickmans_4(Variable(y_batch_output).cuda())[1],\n",
    "                 embeddings=autoencoder_people_4(Variable(X_batch_input_initial).cuda())[1]).cpu().data\n",
    "    \n",
    "    X_batch_input = X_batch_input_initial.clone()\n",
    "    X_batch_input = X_batch_input[(mask4_group_1 + mask4_group_2).nonzero()].view((batch_size, 3, 4, 8))\n",
    "    X_batch_input = Variable(X_batch_input).cuda()\n",
    "    \n",
    "    group_3 = net4_group3(X_batch_input,\n",
    "                 keypoints=autoencoder_stickmans_4(Variable(y_batch_output).cuda())[1],\n",
    "                 embeddings=autoencoder_people_4(Variable(X_batch_input_initial).cuda())[1]).cpu().data\n",
    "    \n",
    "    X_batch_input = X_batch_input_initial.clone()\n",
    "    X_batch_input[(mask4_group_4).nonzero()] = 0\n",
    "    X_batch_input = Variable(X_batch_input).cuda()\n",
    "    \n",
    "    group_4 = net4_group4(X_batch_input,\n",
    "                 keypoints=autoencoder_stickmans_4(Variable(y_batch_output).cuda())[1],\n",
    "                 embeddings=autoencoder_people_4(Variable(X_batch_input_initial).cuda())[1]).cpu().data\n",
    "    \n",
    "    final_image = torch.zeros_like(X_batch_input).cpu().data.float()\n",
    "    final_image[mask4_group_1.nonzero()] = group_1.view(-1).cpu().data.float()\n",
    "    final_image[mask4_group_2.nonzero()] = group_2.view(-1).float()\n",
    "    final_image[mask4_group_3.nonzero()] = group_3.view(-1).float()\n",
    "    final_image[mask4_group_4.nonzero()] = group_4.view(-1).float()\n",
    "#     if is_plot:\n",
    "#         plot_gallery(X_batch[:, 1], 8, 8, 1, 3)\n",
    "#         plot_gallery(final_image, 8, 8, 1, 3)\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim_x = 16\n",
    "batch_size = 64\n",
    "train_loader, val_loader = get_train_loader(\"../deepfashion/index.p\", batch_size=batch_size, resize_size=dim_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net8Group2(nn.Module):\n",
    "    \"\"\"\n",
    "        Network for predictions group 2 images based on group 1.\n",
    "        input size: 4x4\n",
    "        output size: 4x4\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layers=[1], bottelneck_size=32):\n",
    "        super(Net8Group2, self).__init__()\n",
    "        \n",
    "        self.first_part = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=2, padding=0),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.up_1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(96, 64, 2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv_1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv_2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), stride=1, padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, kernel_size=(2, 2), stride=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, keypoints, embeddings):\n",
    "        x = self.first_part(x)\n",
    "        x = torch.cat((x, keypoints, embeddings), dim=1)\n",
    "        x = self.up_1(x)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_input_1 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(dim_x):\n",
    "            for j in range(dim_x):\n",
    "                if i % 2 == 0 and j % 2 ==0:\n",
    "                    mask_input_1[m][n][i][j] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_output_1 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(dim_x):\n",
    "            for j in range(dim_x):\n",
    "                if i % 2 == 0 and j % 2 == 1:\n",
    "                    mask_output_1[m][n][i][j] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "net8_group2 = Net8Group2().cuda()\n",
    "optimizer = optim.Adam(net8_group2.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_network(net, criterion, optimizer, mask_input, mask_output, shape_input, shape_output, num_epochs):\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        net.train(True)\n",
    "        i = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            i += 1\n",
    "            if X_batch.shape[0] != batch_size:\n",
    "                continue\n",
    "            X_batch_input = X_batch[:, 0]\n",
    "            X_batch_input = X_batch_input[mask_input.nonzero()].view(shape_input)\n",
    "            \n",
    "            y_batch_output = y_batch[:, 1]\n",
    "            y_batch_output = y_batch_output[mask_input.nonzero()].view(shape_input)\n",
    "            \n",
    "            X_batch_input = Variable(convert_input_into_image_4(X_batch_input, y_batch_output)).cuda()\n",
    "\n",
    "            X_batch_output = X_batch[:, 1]\n",
    "            X_batch_output = X_batch_output[mask_output.nonzero()].view(shape_output)\n",
    "            X_batch_output = Variable(X_batch_output).cuda()\n",
    "\n",
    "            output_img = net(X_batch_input,\n",
    "                                     keypoints=autoencoder_stickmans_8(Variable(y_batch[:, 1]).cuda())[1],\n",
    "                                     embeddings=autoencoder_people_8(Variable(X_batch[:, 0]).cuda())[1])\n",
    "            loss = criterion(output_img, X_batch_output)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.append(loss.cpu().data.numpy()[0])\n",
    "\n",
    "        # And a full pass over the validation data:\n",
    "    #     autoencoder.train(False) # disable dropout / use averages for batch_norm\n",
    "    #     for X_batch, y_batch in val_loader:\n",
    "    #         X_batch_0 = Variable(y_batch[:, 0]).cuda()\n",
    "    #         output_img, _ = autoencoder(X_batch_0)\n",
    "    #         val_loss.append(criterion(output_img, X_batch_0).cpu().data.numpy()[0])\n",
    "    #         X_batch_1 = Variable(y_batch[:, 1]).cuda()\n",
    "    #         output_img, _ = autoencoder(X_batch_1)\n",
    "    #         val_loss.append(criterion(output_img, X_batch_1).cpu().data.numpy()[0])\n",
    "\n",
    "        print \n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
    "            np.mean(train_loss[-2 * len(train_loader):])))\n",
    "    #     print(\"  validation loss: \\t\\t\\t{:.6f}\".format(\n",
    "    #         np.mean(val_loss[-2 * len(val_loader):])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 100 took 50.293s\n",
      "  training loss (in-iteration): \t0.007564\n",
      "Epoch 2 of 100 took 50.150s\n",
      "  training loss (in-iteration): \t0.007507\n",
      "Epoch 3 of 100 took 50.864s\n",
      "  training loss (in-iteration): \t0.007380\n",
      "Epoch 4 of 100 took 52.429s\n",
      "  training loss (in-iteration): \t0.007247\n",
      "Epoch 5 of 100 took 50.950s\n",
      "  training loss (in-iteration): \t0.007148\n",
      "Epoch 6 of 100 took 49.872s\n",
      "  training loss (in-iteration): \t0.007073\n",
      "Epoch 7 of 100 took 49.489s\n",
      "  training loss (in-iteration): \t0.006967\n",
      "Epoch 8 of 100 took 50.476s\n",
      "  training loss (in-iteration): \t0.006823\n",
      "Epoch 9 of 100 took 50.571s\n",
      "  training loss (in-iteration): \t0.006686\n",
      "Epoch 10 of 100 took 50.592s\n",
      "  training loss (in-iteration): \t0.006595\n",
      "Epoch 11 of 100 took 49.508s\n",
      "  training loss (in-iteration): \t0.006529\n",
      "Epoch 12 of 100 took 49.726s\n",
      "  training loss (in-iteration): \t0.006451\n",
      "Epoch 13 of 100 took 52.540s\n",
      "  training loss (in-iteration): \t0.006376\n",
      "Epoch 14 of 100 took 52.504s\n",
      "  training loss (in-iteration): \t0.006327\n",
      "Epoch 15 of 100 took 51.939s\n",
      "  training loss (in-iteration): \t0.006274\n",
      "Epoch 16 of 100 took 52.627s\n",
      "  training loss (in-iteration): \t0.006214\n",
      "Epoch 17 of 100 took 52.165s\n",
      "  training loss (in-iteration): \t0.006139\n",
      "Epoch 18 of 100 took 52.400s\n",
      "  training loss (in-iteration): \t0.006036\n",
      "Epoch 19 of 100 took 52.839s\n",
      "  training loss (in-iteration): \t0.005941\n",
      "Epoch 20 of 100 took 51.818s\n",
      "  training loss (in-iteration): \t0.005858\n",
      "Epoch 21 of 100 took 53.487s\n",
      "  training loss (in-iteration): \t0.005747\n",
      "Epoch 22 of 100 took 54.173s\n",
      "  training loss (in-iteration): \t0.005651\n",
      "Epoch 23 of 100 took 46.168s\n",
      "  training loss (in-iteration): \t0.005627\n",
      "Epoch 24 of 100 took 53.213s\n",
      "  training loss (in-iteration): \t0.005616\n",
      "Epoch 25 of 100 took 59.182s\n",
      "  training loss (in-iteration): \t0.005572\n",
      "Epoch 26 of 100 took 60.715s\n",
      "  training loss (in-iteration): \t0.005510\n",
      "Epoch 27 of 100 took 60.350s\n",
      "  training loss (in-iteration): \t0.005434\n",
      "Epoch 28 of 100 took 51.717s\n",
      "  training loss (in-iteration): \t0.005364\n",
      "Epoch 29 of 100 took 50.515s\n",
      "  training loss (in-iteration): \t0.005310\n",
      "Epoch 30 of 100 took 50.037s\n",
      "  training loss (in-iteration): \t0.005257\n",
      "Epoch 31 of 100 took 49.892s\n",
      "  training loss (in-iteration): \t0.005218\n",
      "Epoch 32 of 100 took 49.523s\n",
      "  training loss (in-iteration): \t0.005191\n",
      "Epoch 33 of 100 took 49.851s\n",
      "  training loss (in-iteration): \t0.005160\n",
      "Epoch 34 of 100 took 51.999s\n",
      "  training loss (in-iteration): \t0.005133\n",
      "Epoch 35 of 100 took 50.799s\n",
      "  training loss (in-iteration): \t0.005089\n",
      "Epoch 36 of 100 took 50.461s\n",
      "  training loss (in-iteration): \t0.005037\n",
      "Epoch 37 of 100 took 51.057s\n",
      "  training loss (in-iteration): \t0.005027\n",
      "Epoch 38 of 100 took 49.474s\n",
      "  training loss (in-iteration): \t0.005014\n",
      "Epoch 39 of 100 took 50.885s\n",
      "  training loss (in-iteration): \t0.004962\n",
      "Epoch 40 of 100 took 53.533s\n",
      "  training loss (in-iteration): \t0.004922\n",
      "Epoch 41 of 100 took 54.104s\n",
      "  training loss (in-iteration): \t0.004917\n",
      "Epoch 42 of 100 took 51.523s\n",
      "  training loss (in-iteration): \t0.004901\n",
      "Epoch 43 of 100 took 52.325s\n",
      "  training loss (in-iteration): \t0.004855\n",
      "Epoch 44 of 100 took 52.051s\n",
      "  training loss (in-iteration): \t0.004806\n",
      "Epoch 45 of 100 took 50.624s\n",
      "  training loss (in-iteration): \t0.004765\n",
      "Epoch 46 of 100 took 51.079s\n",
      "  training loss (in-iteration): \t0.004714\n",
      "Epoch 47 of 100 took 50.363s\n",
      "  training loss (in-iteration): \t0.004632\n",
      "Epoch 48 of 100 took 50.698s\n",
      "  training loss (in-iteration): \t0.004557\n",
      "Epoch 49 of 100 took 49.018s\n",
      "  training loss (in-iteration): \t0.004486\n",
      "Epoch 50 of 100 took 49.323s\n",
      "  training loss (in-iteration): \t0.004427\n",
      "Epoch 51 of 100 took 49.472s\n",
      "  training loss (in-iteration): \t0.004405\n",
      "Epoch 52 of 100 took 49.168s\n",
      "  training loss (in-iteration): \t0.004410\n",
      "Epoch 53 of 100 took 50.486s\n",
      "  training loss (in-iteration): \t0.004409\n",
      "Epoch 54 of 100 took 58.761s\n",
      "  training loss (in-iteration): \t0.004390\n",
      "Epoch 55 of 100 took 72.648s\n",
      "  training loss (in-iteration): \t0.004348\n",
      "Epoch 56 of 100 took 80.140s\n",
      "  training loss (in-iteration): \t0.004302\n",
      "Epoch 57 of 100 took 58.828s\n",
      "  training loss (in-iteration): \t0.004269\n",
      "Epoch 58 of 100 took 55.919s\n",
      "  training loss (in-iteration): \t0.004248\n",
      "Epoch 59 of 100 took 52.608s\n",
      "  training loss (in-iteration): \t0.004229\n",
      "Epoch 60 of 100 took 51.617s\n",
      "  training loss (in-iteration): \t0.004234\n",
      "Epoch 61 of 100 took 50.508s\n",
      "  training loss (in-iteration): \t0.004256\n",
      "Epoch 62 of 100 took 51.687s\n",
      "  training loss (in-iteration): \t0.004246\n",
      "Epoch 63 of 100 took 52.542s\n",
      "  training loss (in-iteration): \t0.004228\n",
      "Epoch 64 of 100 took 51.652s\n",
      "  training loss (in-iteration): \t0.004218\n",
      "Epoch 65 of 100 took 51.006s\n",
      "  training loss (in-iteration): \t0.004202\n",
      "Epoch 66 of 100 took 50.679s\n",
      "  training loss (in-iteration): \t0.004211\n",
      "Epoch 67 of 100 took 51.487s\n",
      "  training loss (in-iteration): \t0.004263\n",
      "Epoch 68 of 100 took 50.605s\n",
      "  training loss (in-iteration): \t0.004261\n",
      "Epoch 69 of 100 took 59.629s\n",
      "  training loss (in-iteration): \t0.004193\n",
      "Epoch 70 of 100 took 69.380s\n",
      "  training loss (in-iteration): \t0.004156\n",
      "Epoch 71 of 100 took 64.928s\n",
      "  training loss (in-iteration): \t0.004156\n",
      "Epoch 72 of 100 took 59.485s\n",
      "  training loss (in-iteration): \t0.004170\n",
      "Epoch 73 of 100 took 50.804s\n",
      "  training loss (in-iteration): \t0.004176\n",
      "Epoch 74 of 100 took 51.808s\n",
      "  training loss (in-iteration): \t0.004124\n",
      "Epoch 75 of 100 took 52.344s\n",
      "  training loss (in-iteration): \t0.004051\n",
      "Epoch 76 of 100 took 52.825s\n",
      "  training loss (in-iteration): \t0.003971\n",
      "Epoch 77 of 100 took 51.759s\n",
      "  training loss (in-iteration): \t0.003881\n",
      "Epoch 78 of 100 took 50.940s\n",
      "  training loss (in-iteration): \t0.003819\n",
      "Epoch 79 of 100 took 48.703s\n",
      "  training loss (in-iteration): \t0.003775\n",
      "Epoch 80 of 100 took 53.007s\n",
      "  training loss (in-iteration): \t0.003756\n",
      "Epoch 81 of 100 took 68.125s\n",
      "  training loss (in-iteration): \t0.003751\n",
      "Epoch 82 of 100 took 62.819s\n",
      "  training loss (in-iteration): \t0.003738\n",
      "Epoch 83 of 100 took 59.274s\n",
      "  training loss (in-iteration): \t0.003744\n",
      "Epoch 84 of 100 took 50.762s\n",
      "  training loss (in-iteration): \t0.003751\n",
      "Epoch 85 of 100 took 51.614s\n",
      "  training loss (in-iteration): \t0.003761\n",
      "Epoch 86 of 100 took 51.501s\n",
      "  training loss (in-iteration): \t0.003754\n",
      "Epoch 87 of 100 took 51.296s\n",
      "  training loss (in-iteration): \t0.003720\n",
      "Epoch 88 of 100 took 51.934s\n",
      "  training loss (in-iteration): \t0.003697\n",
      "Epoch 89 of 100 took 52.026s\n",
      "  training loss (in-iteration): \t0.003687\n",
      "Epoch 90 of 100 took 50.391s\n",
      "  training loss (in-iteration): \t0.003672\n",
      "Epoch 91 of 100 took 52.916s\n",
      "  training loss (in-iteration): \t0.003659\n",
      "Epoch 92 of 100 took 50.753s\n",
      "  training loss (in-iteration): \t0.003674\n",
      "Epoch 93 of 100 took 53.094s\n",
      "  training loss (in-iteration): \t0.003696\n",
      "Epoch 94 of 100 took 56.330s\n",
      "  training loss (in-iteration): \t0.003689\n",
      "Epoch 95 of 100 took 60.765s\n",
      "  training loss (in-iteration): \t0.003666\n",
      "Epoch 96 of 100 took 59.072s\n",
      "  training loss (in-iteration): \t0.003638\n",
      "Epoch 97 of 100 took 62.009s\n",
      "  training loss (in-iteration): \t0.003607\n",
      "Epoch 98 of 100 took 51.754s\n",
      "  training loss (in-iteration): \t0.003603\n",
      "Epoch 99 of 100 took 52.290s\n",
      "  training loss (in-iteration): \t0.003614\n",
      "Epoch 100 of 100 took 51.207s\n",
      "  training loss (in-iteration): \t0.003603\n"
     ]
    }
   ],
   "source": [
    "train_network(net8_group2, criterion, optimizer, mask_input_1, mask_output_1,\n",
    "              shape_input=(batch_size, 3, int(dim_x / 2), int(dim_x / 2)),\n",
    "              shape_output=(batch_size, 3, int(dim_x / 2), int(dim_x / 2)),\n",
    "              num_epochs=100\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 100 took 51.714s\n",
      "  training loss (in-iteration): \t0.003558\n",
      "Epoch 2 of 100 took 50.972s\n",
      "  training loss (in-iteration): \t0.003554\n",
      "Epoch 3 of 100 took 50.798s\n",
      "  training loss (in-iteration): \t0.003547\n",
      "Epoch 4 of 100 took 50.803s\n",
      "  training loss (in-iteration): \t0.003521\n",
      "Epoch 5 of 100 took 52.934s\n",
      "  training loss (in-iteration): \t0.003478\n",
      "Epoch 6 of 100 took 53.156s\n",
      "  training loss (in-iteration): \t0.003450\n",
      "Epoch 7 of 100 took 51.263s\n",
      "  training loss (in-iteration): \t0.003454\n",
      "Epoch 8 of 100 took 51.995s\n",
      "  training loss (in-iteration): \t0.003462\n",
      "Epoch 9 of 100 took 51.524s\n",
      "  training loss (in-iteration): \t0.003443\n",
      "Epoch 10 of 100 took 51.417s\n",
      "  training loss (in-iteration): \t0.003426\n",
      "Epoch 11 of 100 took 57.189s\n",
      "  training loss (in-iteration): \t0.003412\n",
      "Epoch 12 of 100 took 57.506s\n",
      "  training loss (in-iteration): \t0.003410\n",
      "Epoch 13 of 100 took 60.399s\n",
      "  training loss (in-iteration): \t0.003422\n",
      "Epoch 14 of 100 took 63.957s\n",
      "  training loss (in-iteration): \t0.003419\n",
      "Epoch 15 of 100 took 51.852s\n",
      "  training loss (in-iteration): \t0.003415\n",
      "Epoch 16 of 100 took 51.389s\n",
      "  training loss (in-iteration): \t0.003419\n",
      "Epoch 17 of 100 took 50.839s\n",
      "  training loss (in-iteration): \t0.003414\n",
      "Epoch 18 of 100 took 51.573s\n",
      "  training loss (in-iteration): \t0.003392\n",
      "Epoch 19 of 100 took 49.902s\n",
      "  training loss (in-iteration): \t0.003339\n",
      "Epoch 20 of 100 took 51.108s\n",
      "  training loss (in-iteration): \t0.003288\n",
      "Epoch 21 of 100 took 52.897s\n",
      "  training loss (in-iteration): \t0.003261\n",
      "Epoch 22 of 100 took 53.233s\n",
      "  training loss (in-iteration): \t0.003237\n",
      "Epoch 23 of 100 took 52.165s\n",
      "  training loss (in-iteration): \t0.003226\n",
      "Epoch 24 of 100 took 64.210s\n",
      "  training loss (in-iteration): \t0.003241\n",
      "Epoch 25 of 100 took 90.225s\n",
      "  training loss (in-iteration): \t0.003272\n",
      "Epoch 26 of 100 took 69.869s\n",
      "  training loss (in-iteration): \t0.003268\n",
      "Epoch 27 of 100 took 56.904s\n",
      "  training loss (in-iteration): \t0.003236\n",
      "Epoch 28 of 100 took 50.058s\n",
      "  training loss (in-iteration): \t0.003210\n",
      "Epoch 29 of 100 took 51.911s\n",
      "  training loss (in-iteration): \t0.003199\n",
      "Epoch 30 of 100 took 53.611s\n",
      "  training loss (in-iteration): \t0.003199\n",
      "Epoch 31 of 100 took 50.778s\n",
      "  training loss (in-iteration): \t0.003205\n",
      "Epoch 32 of 100 took 51.046s\n",
      "  training loss (in-iteration): \t0.003214\n"
     ]
    }
   ],
   "source": [
    "train_network(net8_group2, criterion, optimizer, mask_input_1, mask_output_1,\n",
    "              shape_input=(batch_size, 3, int(dim_x / 2), int(dim_x / 2)),\n",
    "              shape_output=(batch_size, 3, int(dim_x / 2), int(dim_x / 2)),\n",
    "              num_epochs=100\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koloskov/anaconda3/lib/python3.6/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type Net8Group2. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(net8_group2, \"net8.group2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net8_group2 = torch.load(\"net8.group2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_gallery(images, h, w, n_row=3, n_col=6):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    scale_const = 1.2\n",
    "    plt.figure(figsize=(3 / scale_const * n_col, 3.4 / scale_const * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].numpy().transpose(1,2,0), cmap=plt.cm.gray, vmin=-1, vmax=1, interpolation='nearest')\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for X_batch, y_batch in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch_input = X_batch[:, 0]\n",
    "X_batch_input = X_batch_input[mask_input_1.nonzero()].view((batch_size, 3, int(dim_x / 2), int(dim_x / 2)))\n",
    "X_batch_input = Variable(X_batch_input).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACxCAYAAADwMnaUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9b003b1278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_gallery(X_batch_input.cpu().data, 8, 8, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACxCAYAAADwMnaUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBABoQ5gAAG38C48NpjE117lTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9b00991358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_batch_input = X_batch[:, 0]\n",
    "X_batch_input = X_batch_input[mask_input_1.nonzero()].view((batch_size, 3, int(dim_x / 2), int(dim_x / 2)))\n",
    "\n",
    "y_batch_output = y_batch[:, 1]\n",
    "y_batch_output = y_batch_output[mask_input_1.nonzero()].view((batch_size, 3, int(dim_x / 2), int(dim_x / 2)))\n",
    "\n",
    "X_batch_input = Variable(convert_input_into_image_4(X_batch_input, y_batch_output)).cuda()\n",
    "\n",
    "X_batch_output = X_batch[:, 1]\n",
    "X_batch_output = X_batch_output[mask_output_1.nonzero()].view((batch_size, 3, int(dim_x / 2), int(dim_x / 2)))\n",
    "X_batch_output = Variable(X_batch_output).cuda()\n",
    "plot_gallery(net8_group2(X_batch_input,\n",
    "                 keypoints=autoencoder_stickmans_8(Variable(y_batch[:, 1]).cuda())[1],\n",
    "                 embeddings=autoencoder_people_8(Variable(X_batch[:, 0]).cuda())[1]).cpu().data,\n",
    "             8, 8, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch_output = X_batch[:, 1]\n",
    "X_batch_output = X_batch_output[mask_output_1.nonzero()].view((batch_size, 3, int(dim_x / 2), int(dim_x / 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACxCAYAAADwMnaUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9b00160cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_gallery(X_batch_output, 8, 8, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net8Group3(nn.Module):\n",
    "    \"\"\"\n",
    "        Network for predictions group 2 images based on group 1.\n",
    "        input size: 4x4\n",
    "        output size: 4x4\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layers=[1], bottelneck_size=32):\n",
    "        super(Net8Group3, self).__init__()\n",
    "        \n",
    "        self.first_part = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=2, padding=0),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=(1, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(1, 3)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.up_1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(96, 64, 2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv_1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv_2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), stride=1, padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, kernel_size=(2, 2), stride=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, keypoints, embeddings):\n",
    "        x = self.first_part(x)\n",
    "#         print(x.shape)\n",
    "        x = torch.cat((x, keypoints, embeddings), dim=1)\n",
    "        x = self.up_1(x)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network_group_3(net, criterion, optimizer, mask_input, mask_output, shape_input, shape_output, num_epochs):\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    \n",
    "    mask_first_part = np.zeros((batch_size, 3, int(dim_x / 2), dim_x)).astype(bool)\n",
    "    for m in range(batch_size):\n",
    "        for n in range(3):\n",
    "            for i in range(int(dim_x/2)):\n",
    "                for j in range(dim_x):\n",
    "                    if j % 2 == 0:\n",
    "                        mask_first_part[m][n][i][j] = True\n",
    "    mask_second_part = np.zeros((batch_size, 3, int(dim_x / 2), dim_x)).astype(bool)\n",
    "    for m in range(batch_size):\n",
    "        for n in range(3):\n",
    "            for i in range(int(dim_x/2)):\n",
    "                for j in range(dim_x):\n",
    "                    if j % 2 == 1:\n",
    "                        mask_second_part[m][n][i][j] = True\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        net.train(True)\n",
    "        i = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            i += 1\n",
    "            if X_batch.shape[0] != batch_size:\n",
    "                continue\n",
    "            X_batch_input = X_batch[:, 0]\n",
    "            X_batch_input = X_batch_input[mask_input.nonzero()].view(shape_output)\n",
    "            \n",
    "            y_batch_output = y_batch[:, 1]\n",
    "            y_batch_output = y_batch_output[mask_input.nonzero()].view(shape_output)\n",
    "            \n",
    "            X_batch_input = Variable(convert_input_into_image_4(X_batch_input, y_batch_output)).cuda()\n",
    "            X_batch_group_2 = net8_group2(X_batch_input,\n",
    "                 keypoints=autoencoder_stickmans_8(Variable(y_batch[:, 1]).cuda())[1],\n",
    "                 embeddings=autoencoder_people_8(Variable(X_batch[:, 0]).cuda())[1])\n",
    "#             print(X_batch_input.shape)\n",
    "#             print(X_batch_group_2.shape)\n",
    "            X_cur_input = Variable(torch.zeros(shape_input)).cuda().float()\n",
    "            X_cur_input[mask_first_part.nonzero()] = X_batch_input.view(-1).float()\n",
    "            X_cur_input[mask_second_part.nonzero()] = X_batch_group_2.view(-1).float()\n",
    "#             print(X_cur_input.shape)\n",
    "            X_batch_output = X_batch[:, 1]\n",
    "            X_batch_output = X_batch_output[mask_output.nonzero()].view(shape_output)\n",
    "            X_batch_output = Variable(X_batch_output).cuda()\n",
    "\n",
    "            output_img = net(X_cur_input,\n",
    "                                     keypoints=autoencoder_stickmans_8(Variable(y_batch[:, 1]).cuda())[1],\n",
    "                                     embeddings=autoencoder_people_8(Variable(X_batch[:, 0]).cuda())[1])\n",
    "            loss = criterion(output_img, X_batch_output)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.append(loss.cpu().data.numpy()[0])\n",
    "\n",
    "        # And a full pass over the validation data:\n",
    "    #     autoencoder.train(False) # disable dropout / use averages for batch_norm\n",
    "    #     for X_batch, y_batch in val_loader:\n",
    "    #         X_batch_0 = Variable(y_batch[:, 0]).cuda()\n",
    "    #         output_img, _ = autoencoder(X_batch_0)\n",
    "    #         val_loss.append(criterion(output_img, X_batch_0).cpu().data.numpy()[0])\n",
    "    #         X_batch_1 = Variable(y_batch[:, 1]).cuda()\n",
    "    #         output_img, _ = autoencoder(X_batch_1)\n",
    "    #         val_loss.append(criterion(output_img, X_batch_1).cpu().data.numpy()[0])\n",
    "\n",
    "        print \n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
    "            np.mean(train_loss[-2 * len(train_loader):])))\n",
    "    #     print(\"  validation loss: \\t\\t\\t{:.6f}\".format(\n",
    "    #         np.mean(val_loss[-2 * len(val_loader):])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mask_input_2 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "# for m in range(batch_size):\n",
    "#     for n in range(3):\n",
    "#         for i in range(dim_x):\n",
    "#             for j in range(dim_x):\n",
    "#                 if i % 2 == 0:\n",
    "#                     mask_input_2[m][n][i][j] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_output_2 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(dim_x):\n",
    "            for j in range(dim_x):\n",
    "                if i % 2 == 1 and j % 2 == 0:\n",
    "                    mask_output_2[m][n][i][j] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "net8_group3 = Net8Group3().cuda()\n",
    "optimizer = optim.Adam(net8_group3.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 100 took 51.245s\n",
      "  training loss (in-iteration): \t0.022289\n",
      "Epoch 2 of 100 took 49.976s\n",
      "  training loss (in-iteration): \t0.015648\n",
      "Epoch 3 of 100 took 49.572s\n",
      "  training loss (in-iteration): \t0.008548\n",
      "Epoch 4 of 100 took 51.880s\n",
      "  training loss (in-iteration): \t0.007852\n",
      "Epoch 5 of 100 took 52.138s\n",
      "  training loss (in-iteration): \t0.007489\n",
      "Epoch 6 of 100 took 56.786s\n",
      "  training loss (in-iteration): \t0.007235\n",
      "Epoch 7 of 100 took 53.878s\n",
      "  training loss (in-iteration): \t0.007012\n",
      "Epoch 8 of 100 took 60.878s\n",
      "  training loss (in-iteration): \t0.006830\n",
      "Epoch 9 of 100 took 55.050s\n",
      "  training loss (in-iteration): \t0.006679\n",
      "Epoch 10 of 100 took 49.213s\n",
      "  training loss (in-iteration): \t0.006535\n",
      "Epoch 11 of 100 took 51.549s\n",
      "  training loss (in-iteration): \t0.006414\n",
      "Epoch 12 of 100 took 52.666s\n",
      "  training loss (in-iteration): \t0.006313\n",
      "Epoch 13 of 100 took 50.548s\n",
      "  training loss (in-iteration): \t0.006206\n",
      "Epoch 14 of 100 took 50.047s\n",
      "  training loss (in-iteration): \t0.006083\n",
      "Epoch 15 of 100 took 53.562s\n",
      "  training loss (in-iteration): \t0.005979\n",
      "Epoch 16 of 100 took 50.498s\n",
      "  training loss (in-iteration): \t0.005899\n",
      "Epoch 17 of 100 took 50.423s\n",
      "  training loss (in-iteration): \t0.005833\n",
      "Epoch 18 of 100 took 49.836s\n",
      "  training loss (in-iteration): \t0.005763\n",
      "Epoch 19 of 100 took 48.249s\n",
      "  training loss (in-iteration): \t0.005690\n",
      "Epoch 20 of 100 took 49.255s\n",
      "  training loss (in-iteration): \t0.005631\n",
      "Epoch 21 of 100 took 49.437s\n",
      "  training loss (in-iteration): \t0.005545\n",
      "Epoch 22 of 100 took 48.863s\n",
      "  training loss (in-iteration): \t0.005429\n",
      "Epoch 23 of 100 took 48.705s\n",
      "  training loss (in-iteration): \t0.005325\n",
      "Epoch 24 of 100 took 53.180s\n",
      "  training loss (in-iteration): \t0.005251\n",
      "Epoch 25 of 100 took 55.571s\n",
      "  training loss (in-iteration): \t0.005194\n",
      "Epoch 26 of 100 took 63.024s\n",
      "  training loss (in-iteration): \t0.005136\n",
      "Epoch 27 of 100 took 57.375s\n",
      "  training loss (in-iteration): \t0.005080\n",
      "Epoch 28 of 100 took 56.985s\n",
      "  training loss (in-iteration): \t0.005033\n",
      "Epoch 29 of 100 took 49.227s\n",
      "  training loss (in-iteration): \t0.004980\n",
      "Epoch 30 of 100 took 49.526s\n",
      "  training loss (in-iteration): \t0.004937\n",
      "Epoch 31 of 100 took 50.044s\n",
      "  training loss (in-iteration): \t0.004934\n",
      "Epoch 32 of 100 took 49.037s\n",
      "  training loss (in-iteration): \t0.004898\n",
      "Epoch 33 of 100 took 49.891s\n",
      "  training loss (in-iteration): \t0.004824\n",
      "Epoch 34 of 100 took 51.546s\n",
      "  training loss (in-iteration): \t0.004743\n",
      "Epoch 35 of 100 took 51.304s\n",
      "  training loss (in-iteration): \t0.004673\n",
      "Epoch 36 of 100 took 52.128s\n",
      "  training loss (in-iteration): \t0.004634\n",
      "Epoch 37 of 100 took 50.552s\n",
      "  training loss (in-iteration): \t0.004615\n",
      "Epoch 38 of 100 took 51.684s\n",
      "  training loss (in-iteration): \t0.004593\n",
      "Epoch 39 of 100 took 49.117s\n",
      "  training loss (in-iteration): \t0.004550\n",
      "Epoch 40 of 100 took 49.732s\n",
      "  training loss (in-iteration): \t0.004507\n",
      "Epoch 41 of 100 took 49.886s\n",
      "  training loss (in-iteration): \t0.004439\n",
      "Epoch 42 of 100 took 49.612s\n",
      "  training loss (in-iteration): \t0.004389\n",
      "Epoch 43 of 100 took 48.967s\n",
      "  training loss (in-iteration): \t0.004386\n",
      "Epoch 44 of 100 took 48.669s\n",
      "  training loss (in-iteration): \t0.004352\n",
      "Epoch 45 of 100 took 54.514s\n",
      "  training loss (in-iteration): \t0.004291\n",
      "Epoch 46 of 100 took 49.918s\n",
      "  training loss (in-iteration): \t0.004226\n",
      "Epoch 47 of 100 took 50.781s\n",
      "  training loss (in-iteration): \t0.004155\n",
      "Epoch 48 of 100 took 50.726s\n",
      "  training loss (in-iteration): \t0.004094\n",
      "Epoch 49 of 100 took 51.258s\n",
      "  training loss (in-iteration): \t0.004041\n",
      "Epoch 50 of 100 took 49.171s\n",
      "  training loss (in-iteration): \t0.004013\n",
      "Epoch 51 of 100 took 50.840s\n",
      "  training loss (in-iteration): \t0.004016\n",
      "Epoch 52 of 100 took 49.649s\n",
      "  training loss (in-iteration): \t0.004017\n",
      "Epoch 53 of 100 took 51.407s\n",
      "  training loss (in-iteration): \t0.004011\n",
      "Epoch 54 of 100 took 50.330s\n",
      "  training loss (in-iteration): \t0.004033\n",
      "Epoch 55 of 100 took 49.425s\n",
      "  training loss (in-iteration): \t0.004026\n",
      "Epoch 56 of 100 took 49.974s\n",
      "  training loss (in-iteration): \t0.003993\n",
      "Epoch 57 of 100 took 62.415s\n",
      "  training loss (in-iteration): \t0.003958\n",
      "Epoch 58 of 100 took 80.155s\n",
      "  training loss (in-iteration): \t0.003910\n",
      "Epoch 59 of 100 took 63.968s\n",
      "  training loss (in-iteration): \t0.003871\n",
      "Epoch 60 of 100 took 55.921s\n",
      "  training loss (in-iteration): \t0.003850\n",
      "Epoch 61 of 100 took 54.289s\n",
      "  training loss (in-iteration): \t0.003819\n",
      "Epoch 62 of 100 took 51.251s\n",
      "  training loss (in-iteration): \t0.003771\n",
      "Epoch 63 of 100 took 49.840s\n",
      "  training loss (in-iteration): \t0.003724\n",
      "Epoch 64 of 100 took 49.098s\n",
      "  training loss (in-iteration): \t0.003710\n",
      "Epoch 65 of 100 took 50.200s\n",
      "  training loss (in-iteration): \t0.003732\n",
      "Epoch 66 of 100 took 49.989s\n",
      "  training loss (in-iteration): \t0.003735\n",
      "Epoch 67 of 100 took 50.023s\n",
      "  training loss (in-iteration): \t0.003711\n",
      "Epoch 68 of 100 took 49.519s\n",
      "  training loss (in-iteration): \t0.003677\n",
      "Epoch 69 of 100 took 48.064s\n",
      "  training loss (in-iteration): \t0.003642\n",
      "Epoch 70 of 100 took 48.065s\n",
      "  training loss (in-iteration): \t0.003600\n",
      "Epoch 71 of 100 took 48.125s\n",
      "  training loss (in-iteration): \t0.003560\n",
      "Epoch 72 of 100 took 49.699s\n",
      "  training loss (in-iteration): \t0.003536\n",
      "Epoch 73 of 100 took 51.201s\n",
      "  training loss (in-iteration): \t0.003522\n",
      "Epoch 74 of 100 took 51.734s\n",
      "  training loss (in-iteration): \t0.003518\n",
      "Epoch 75 of 100 took 52.966s\n",
      "  training loss (in-iteration): \t0.003515\n",
      "Epoch 76 of 100 took 50.026s\n",
      "  training loss (in-iteration): \t0.003519\n",
      "Epoch 77 of 100 took 52.816s\n",
      "  training loss (in-iteration): \t0.003508\n",
      "Epoch 78 of 100 took 51.170s\n",
      "  training loss (in-iteration): \t0.003457\n",
      "Epoch 79 of 100 took 48.960s\n",
      "  training loss (in-iteration): \t0.003419\n",
      "Epoch 80 of 100 took 49.929s\n",
      "  training loss (in-iteration): \t0.003399\n",
      "Epoch 81 of 100 took 49.369s\n",
      "  training loss (in-iteration): \t0.003379\n",
      "Epoch 82 of 100 took 51.730s\n",
      "  training loss (in-iteration): \t0.003383\n",
      "Epoch 83 of 100 took 51.760s\n",
      "  training loss (in-iteration): \t0.003380\n",
      "Epoch 84 of 100 took 48.478s\n",
      "  training loss (in-iteration): \t0.003352\n",
      "Epoch 85 of 100 took 48.264s\n",
      "  training loss (in-iteration): \t0.003341\n",
      "Epoch 86 of 100 took 50.438s\n",
      "  training loss (in-iteration): \t0.003340\n",
      "Epoch 87 of 100 took 51.158s\n",
      "  training loss (in-iteration): \t0.003332\n",
      "Epoch 88 of 100 took 51.740s\n",
      "  training loss (in-iteration): \t0.003328\n",
      "Epoch 89 of 100 took 50.536s\n",
      "  training loss (in-iteration): \t0.003315\n",
      "Epoch 90 of 100 took 49.844s\n",
      "  training loss (in-iteration): \t0.003314\n",
      "Epoch 91 of 100 took 53.942s\n",
      "  training loss (in-iteration): \t0.003311\n",
      "Epoch 92 of 100 took 68.826s\n",
      "  training loss (in-iteration): \t0.003290\n",
      "Epoch 93 of 100 took 76.024s\n",
      "  training loss (in-iteration): \t0.003274\n",
      "Epoch 94 of 100 took 61.524s\n",
      "  training loss (in-iteration): \t0.003268\n",
      "Epoch 95 of 100 took 48.790s\n",
      "  training loss (in-iteration): \t0.003254\n",
      "Epoch 96 of 100 took 48.328s\n",
      "  training loss (in-iteration): \t0.003212\n",
      "Epoch 97 of 100 took 49.308s\n",
      "  training loss (in-iteration): \t0.003173\n",
      "Epoch 98 of 100 took 49.377s\n",
      "  training loss (in-iteration): \t0.003153\n",
      "Epoch 99 of 100 took 50.592s\n",
      "  training loss (in-iteration): \t0.003133\n",
      "Epoch 100 of 100 took 49.782s\n",
      "  training loss (in-iteration): \t0.003106\n"
     ]
    }
   ],
   "source": [
    "train_network_group_3(net8_group3, criterion, optimizer, mask_input_1, mask_output_2,\n",
    "              shape_input=(batch_size, 3, int(dim_x / 2), int(dim_x)),\n",
    "              shape_output=(batch_size, 3, int(dim_x / 2), int(dim_x / 2)),\n",
    "              num_epochs=100\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koloskov/anaconda3/lib/python3.6/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type Net8Group3. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(net8_group3, \"net8.group3.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAABjCAYAAACvxMuwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAILxTxI+xoIBf1lgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3ae1522d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for X_batch, y_batch in train_loader:\n",
    "    break\n",
    "mask_first_part = np.zeros((batch_size, 3, int(dim_x / 2), dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(int(dim_x/2)):\n",
    "            for j in range(dim_x):\n",
    "                if j % 2 == 0:\n",
    "                    mask_first_part[m][n][i][j] = True\n",
    "mask_second_part = np.zeros((batch_size, 3, int(dim_x / 2), dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(int(dim_x/2)):\n",
    "            for j in range(dim_x):\n",
    "                if j % 2 == 1:\n",
    "                    mask_second_part[m][n][i][j] = True\n",
    "\n",
    "X_batch_input = X_batch[:, 0]\n",
    "X_batch_input = X_batch_input[mask_input_1.nonzero()].view((batch_size, 3, int(dim_x / 2), int(dim_x / 2)))\n",
    "y_batch_output = y_batch[:, 1]\n",
    "y_batch_output = y_batch_output[mask_input_1.nonzero()].view((batch_size, 3, int(dim_x / 2), int(dim_x / 2)))\n",
    "\n",
    "X_batch_input = Variable(convert_input_into_image_4(X_batch_input, y_batch_output)).cuda()\n",
    "X_batch_group_2 = net8_group2(X_batch_input,\n",
    "     keypoints=autoencoder_stickmans_8(Variable(y_batch[:, 1]).cuda())[1],\n",
    "     embeddings=autoencoder_people_8(Variable(X_batch[:, 0]).cuda())[1])\n",
    "#             print(X_batch_input.shape)\n",
    "#             print(X_batch_group_2.shape)\n",
    "X_cur_input = Variable(torch.zeros((batch_size, 3, int(dim_x / 2), int(dim_x)))).cuda().float()\n",
    "X_cur_input[mask_first_part.nonzero()] = X_batch_input.view(-1).float()\n",
    "X_cur_input[mask_second_part.nonzero()] = X_batch_group_2.view(-1).float()\n",
    "plot_gallery(X_cur_input.cpu().data, 8, 8, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACxCAYAAADwMnaUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZriCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3ad88efa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_gallery(net8_group3(X_cur_input,\n",
    "                 keypoints=autoencoder_stickmans_8(Variable(y_batch[:, 1]).cuda())[1],\n",
    "                 embeddings=autoencoder_people_8(Variable(X_batch[:, 0]).cuda())[1]).cpu().data,\n",
    "             8, 8, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACxCAYAAADwMnaUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nECYAQBvCBABoQ5gAAG0IEwCgjX8DhQwUTwYGJVQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3ad8884470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_batch_output = X_batch[:, 1]\n",
    "X_batch_output = X_batch_output[mask_output_2.nonzero()].view((batch_size, 3, int(dim_x / 2), int(dim_x / 2)))\n",
    "plot_gallery(X_batch_output, 8, 8, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask8_group_1 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(dim_x):\n",
    "            for j in range(dim_x):\n",
    "                if i % 2 == 0 and j % 2 == 0:\n",
    "                    mask8_group_1[m][n][i][j] = True\n",
    "mask8_group_2 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(dim_x):\n",
    "            for j in range(dim_x):\n",
    "                if i % 2 == 0 and j % 2 == 1:\n",
    "                    mask8_group_2[m][n][i][j] = True\n",
    "\n",
    "mask8_group_3 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(dim_x):\n",
    "            for j in range(dim_x):\n",
    "                if i % 2 == 1 and j % 2 == 0:\n",
    "                    mask8_group_3[m][n][i][j] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_group4_network(net, criterion, optimizer, mask_input, mask_output, shape_output, num_epochs):\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    \n",
    "    mask_first_part = np.zeros((batch_size, 3, int(dim_x / 2), dim_x)).astype(bool)\n",
    "    for m in range(batch_size):\n",
    "        for n in range(3):\n",
    "            for i in range(int(dim_x/2)):\n",
    "                for j in range(dim_x):\n",
    "                    if j % 2 == 0:\n",
    "                        mask_first_part[m][n][i][j] = True\n",
    "    mask_second_part = np.zeros((batch_size, 3, int(dim_x / 2), dim_x)).astype(bool)\n",
    "    for m in range(batch_size):\n",
    "        for n in range(3):\n",
    "            for i in range(int(dim_x/2)):\n",
    "                for j in range(dim_x):\n",
    "                    if j % 2 == 1:\n",
    "                        mask_second_part[m][n][i][j] = True\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        net.train(True)\n",
    "        i = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            i += 1\n",
    "            if X_batch.shape[0] != batch_size:\n",
    "                continue\n",
    "#             X_batch_input = X_batch[:, 0]\n",
    "#             X_batch_input[(~mask_input).nonzero()] = 0\n",
    "#             X_batch_input = Variable(X_batch_input).cuda()\n",
    "\n",
    "#             X_batch_output = X_batch[:, 1]\n",
    "#             X_batch_output = X_batch_output[mask_output.nonzero()].view(shape_output)\n",
    "#             X_batch_output = Variable(X_batch_output).cuda()\n",
    "\n",
    "            X_batch_input = X_batch[:, 0]\n",
    "            X_batch_input = X_batch_input[mask_input.nonzero()].view(shape_output)\n",
    "            \n",
    "            y_batch_output = y_batch[:, 1]\n",
    "            y_batch_output = y_batch_output[mask_input.nonzero()].view(shape_output)\n",
    "            \n",
    "            X_batch_input = Variable(convert_input_into_image_4(X_batch_input, y_batch_output)).cuda()\n",
    "            X_batch_group_2 = net8_group2(X_batch_input,\n",
    "                 keypoints=autoencoder_stickmans_8(Variable(y_batch[:, 1]).cuda())[1],\n",
    "                 embeddings=autoencoder_people_8(Variable(X_batch[:, 0]).cuda())[1])\n",
    "#             print(X_batch_input.shape)\n",
    "            X_cur_input = Variable(torch.zeros((batch_size, 3, int(dim_x / 2), dim_x))).cuda().float()\n",
    "            X_cur_input[mask_first_part.nonzero()] = X_batch_input.view(-1).float()\n",
    "            X_cur_input[mask_second_part.nonzero()] = X_batch_group_2.view(-1).float()\n",
    "            X_batch_group_3 = net8_group3(X_cur_input,\n",
    "                 keypoints=autoencoder_stickmans_8(Variable(y_batch[:, 1]).cuda())[1],\n",
    "                 embeddings=autoencoder_people_8(Variable(X_batch[:, 0]).cuda())[1])\n",
    "#             print(X_cur_input.shape)\n",
    "\n",
    "            X_cur_input = Variable(torch.zeros((batch_size, 3, dim_x, dim_x))).cuda().float()\n",
    "            X_cur_input[mask8_group_1.nonzero()] = X_batch_input.view(-1).float()\n",
    "            X_cur_input[mask8_group_2.nonzero()] = X_batch_group_2.view(-1).float()\n",
    "            X_cur_input[mask8_group_3.nonzero()] = X_batch_group_3.view(-1).float()\n",
    "    \n",
    "            X_batch_output = X_batch[:, 1]\n",
    "            X_batch_output = X_batch_output[mask_output.nonzero()].view(shape_output)\n",
    "            X_batch_output = Variable(X_batch_output).cuda()\n",
    "\n",
    "            output_img = net(X_cur_input,\n",
    "                             keypoints=autoencoder_stickmans_8(Variable(y_batch[:, 1]).cuda())[1],\n",
    "                             embeddings=autoencoder_people_8(Variable(X_batch[:, 0]).cuda())[1])\n",
    "            loss = criterion(output_img, X_batch_output)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.append(loss.cpu().data.numpy()[0])\n",
    "\n",
    "        # And a full pass over the validation data:\n",
    "    #     autoencoder.train(False) # disable dropout / use averages for batch_norm\n",
    "    #     for X_batch, y_batch in val_loader:\n",
    "    #         X_batch_0 = Variable(y_batch[:, 0]).cuda()\n",
    "    #         output_img, _ = autoencoder(X_batch_0)\n",
    "    #         val_loss.append(criterion(output_img, X_batch_0).cpu().data.numpy()[0])\n",
    "    #         X_batch_1 = Variable(y_batch[:, 1]).cuda()\n",
    "    #         output_img, _ = autoencoder(X_batch_1)\n",
    "    #         val_loss.append(criterion(output_img, X_batch_1).cpu().data.numpy()[0])\n",
    "\n",
    "        print \n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
    "            np.mean(train_loss[-2 * len(train_loader):])))\n",
    "    #     print(\"  validation loss: \\t\\t\\t{:.6f}\".format(\n",
    "    #         np.mean(val_loss[-2 * len(val_loader):])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net8Group4(nn.Module):\n",
    "    \"\"\"\n",
    "        Network for predictions group 2 images based on group 1.\n",
    "        input size: 4x4\n",
    "        output size: 4x4\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layers=[1], bottelneck_size=32):\n",
    "        super(Net8Group4, self).__init__()\n",
    "        \n",
    "        self.first_part = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=2, padding=0),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=2, padding=1),\n",
    "#             nn.MaxPool2d(2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.up_1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(96, 64, 2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv_1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv_2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), stride=1, padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, kernel_size=(2, 2), stride=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, keypoints, embeddings):\n",
    "        x = self.first_part(x)\n",
    "        x = torch.cat((x, keypoints, embeddings), dim=1)\n",
    "        x = self.up_1(x)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mask_input_3 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "# for m in range(batch_size):\n",
    "#     for n in range(3):\n",
    "#         for i in range(dim_x):\n",
    "#             for j in range(dim_x):\n",
    "#                 if i % 2 == 0 or j % 2 == 0:\n",
    "#                     mask_input_3[m][n][i][j] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_output_3 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(dim_x):\n",
    "            for j in range(dim_x):\n",
    "                if i % 2 == 1 and j % 2 == 1:\n",
    "                    mask_output_3[m][n][i][j] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "net8_group4 = Net8Group4().cuda()\n",
    "optimizer = optim.Adam(net8_group4.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 100 took 54.448s\n",
      "  training loss (in-iteration): \t0.017257\n",
      "Epoch 2 of 100 took 53.941s\n",
      "  training loss (in-iteration): \t0.011796\n",
      "Epoch 3 of 100 took 55.410s\n",
      "  training loss (in-iteration): \t0.005985\n",
      "Epoch 4 of 100 took 53.873s\n",
      "  training loss (in-iteration): \t0.005445\n",
      "Epoch 5 of 100 took 54.621s\n",
      "  training loss (in-iteration): \t0.005154\n",
      "Epoch 6 of 100 took 53.112s\n",
      "  training loss (in-iteration): \t0.004966\n",
      "Epoch 7 of 100 took 53.553s\n",
      "  training loss (in-iteration): \t0.004834\n",
      "Epoch 8 of 100 took 54.650s\n",
      "  training loss (in-iteration): \t0.004739\n",
      "Epoch 9 of 100 took 54.624s\n",
      "  training loss (in-iteration): \t0.004653\n",
      "Epoch 10 of 100 took 53.418s\n",
      "  training loss (in-iteration): \t0.004558\n",
      "Epoch 11 of 100 took 55.628s\n",
      "  training loss (in-iteration): \t0.004470\n",
      "Epoch 12 of 100 took 54.433s\n",
      "  training loss (in-iteration): \t0.004396\n",
      "Epoch 13 of 100 took 58.203s\n",
      "  training loss (in-iteration): \t0.004337\n",
      "Epoch 14 of 100 took 77.587s\n",
      "  training loss (in-iteration): \t0.004286\n",
      "Epoch 15 of 100 took 84.476s\n",
      "  training loss (in-iteration): \t0.004234\n",
      "Epoch 16 of 100 took 83.595s\n",
      "  training loss (in-iteration): \t0.004180\n",
      "Epoch 17 of 100 took 78.380s\n",
      "  training loss (in-iteration): \t0.004123\n",
      "Epoch 18 of 100 took 58.541s\n",
      "  training loss (in-iteration): \t0.004071\n",
      "Epoch 19 of 100 took 56.127s\n",
      "  training loss (in-iteration): \t0.004024\n",
      "Epoch 20 of 100 took 54.965s\n",
      "  training loss (in-iteration): \t0.003985\n",
      "Epoch 21 of 100 took 56.317s\n",
      "  training loss (in-iteration): \t0.003948\n",
      "Epoch 22 of 100 took 55.516s\n",
      "  training loss (in-iteration): \t0.003911\n",
      "Epoch 23 of 100 took 55.045s\n",
      "  training loss (in-iteration): \t0.003871\n",
      "Epoch 24 of 100 took 56.167s\n",
      "  training loss (in-iteration): \t0.003833\n",
      "Epoch 25 of 100 took 54.479s\n",
      "  training loss (in-iteration): \t0.003802\n",
      "Epoch 26 of 100 took 56.002s\n",
      "  training loss (in-iteration): \t0.003768\n",
      "Epoch 27 of 100 took 55.287s\n",
      "  training loss (in-iteration): \t0.003729\n",
      "Epoch 28 of 100 took 55.310s\n",
      "  training loss (in-iteration): \t0.003700\n",
      "Epoch 29 of 100 took 55.635s\n",
      "  training loss (in-iteration): \t0.003679\n",
      "Epoch 30 of 100 took 77.772s\n",
      "  training loss (in-iteration): \t0.003649\n",
      "Epoch 31 of 100 took 82.804s\n",
      "  training loss (in-iteration): \t0.003614\n",
      "Epoch 32 of 100 took 77.544s\n",
      "  training loss (in-iteration): \t0.003566\n",
      "Epoch 33 of 100 took 56.509s\n",
      "  training loss (in-iteration): \t0.003501\n",
      "Epoch 34 of 100 took 53.875s\n",
      "  training loss (in-iteration): \t0.003448\n",
      "Epoch 35 of 100 took 55.476s\n",
      "  training loss (in-iteration): \t0.003421\n",
      "Epoch 36 of 100 took 55.276s\n",
      "  training loss (in-iteration): \t0.003412\n",
      "Epoch 37 of 100 took 54.065s\n",
      "  training loss (in-iteration): \t0.003400\n",
      "Epoch 38 of 100 took 53.131s\n",
      "  training loss (in-iteration): \t0.003381\n",
      "Epoch 39 of 100 took 53.206s\n",
      "  training loss (in-iteration): \t0.003345\n",
      "Epoch 40 of 100 took 52.517s\n",
      "  training loss (in-iteration): \t0.003290\n",
      "Epoch 41 of 100 took 53.299s\n",
      "  training loss (in-iteration): \t0.003247\n",
      "Epoch 42 of 100 took 54.311s\n",
      "  training loss (in-iteration): \t0.003221\n",
      "Epoch 43 of 100 took 52.786s\n",
      "  training loss (in-iteration): \t0.003197\n",
      "Epoch 44 of 100 took 72.811s\n",
      "  training loss (in-iteration): \t0.003176\n",
      "Epoch 45 of 100 took 74.496s\n",
      "  training loss (in-iteration): \t0.003168\n",
      "Epoch 46 of 100 took 73.053s\n",
      "  training loss (in-iteration): \t0.003156\n",
      "Epoch 47 of 100 took 58.232s\n",
      "  training loss (in-iteration): \t0.003130\n",
      "Epoch 48 of 100 took 55.521s\n",
      "  training loss (in-iteration): \t0.003100\n",
      "Epoch 49 of 100 took 57.213s\n",
      "  training loss (in-iteration): \t0.003064\n",
      "Epoch 50 of 100 took 55.610s\n",
      "  training loss (in-iteration): \t0.003027\n",
      "Epoch 51 of 100 took 56.622s\n",
      "  training loss (in-iteration): \t0.002997\n",
      "Epoch 52 of 100 took 51.516s\n",
      "  training loss (in-iteration): \t0.002974\n",
      "Epoch 53 of 100 took 53.702s\n",
      "  training loss (in-iteration): \t0.002956\n",
      "Epoch 54 of 100 took 56.949s\n",
      "  training loss (in-iteration): \t0.002944\n",
      "Epoch 55 of 100 took 64.397s\n",
      "  training loss (in-iteration): \t0.002926\n",
      "Epoch 56 of 100 took 71.729s\n",
      "  training loss (in-iteration): \t0.002915\n",
      "Epoch 57 of 100 took 65.203s\n",
      "  training loss (in-iteration): \t0.002918\n",
      "Epoch 58 of 100 took 63.080s\n",
      "  training loss (in-iteration): \t0.002906\n",
      "Epoch 59 of 100 took 52.945s\n",
      "  training loss (in-iteration): \t0.002893\n",
      "Epoch 60 of 100 took 55.283s\n",
      "  training loss (in-iteration): \t0.002871\n",
      "Epoch 61 of 100 took 54.043s\n",
      "  training loss (in-iteration): \t0.002842\n",
      "Epoch 62 of 100 took 51.229s\n",
      "  training loss (in-iteration): \t0.002819\n",
      "Epoch 63 of 100 took 54.975s\n",
      "  training loss (in-iteration): \t0.002805\n",
      "Epoch 64 of 100 took 54.731s\n",
      "  training loss (in-iteration): \t0.002804\n",
      "Epoch 65 of 100 took 54.492s\n",
      "  training loss (in-iteration): \t0.002816\n",
      "Epoch 66 of 100 took 62.568s\n",
      "  training loss (in-iteration): \t0.002818\n",
      "Epoch 67 of 100 took 68.135s\n",
      "  training loss (in-iteration): \t0.002789\n",
      "Epoch 68 of 100 took 75.085s\n",
      "  training loss (in-iteration): \t0.002749\n",
      "Epoch 69 of 100 took 65.448s\n",
      "  training loss (in-iteration): \t0.002708\n",
      "Epoch 70 of 100 took 52.694s\n",
      "  training loss (in-iteration): \t0.002667\n",
      "Epoch 71 of 100 took 54.090s\n",
      "  training loss (in-iteration): \t0.002633\n",
      "Epoch 72 of 100 took 54.093s\n",
      "  training loss (in-iteration): \t0.002619\n",
      "Epoch 73 of 100 took 54.639s\n",
      "  training loss (in-iteration): \t0.002612\n",
      "Epoch 74 of 100 took 54.610s\n",
      "  training loss (in-iteration): \t0.002604\n",
      "Epoch 75 of 100 took 54.894s\n",
      "  training loss (in-iteration): \t0.002604\n",
      "Epoch 76 of 100 took 53.487s\n",
      "  training loss (in-iteration): \t0.002601\n",
      "Epoch 77 of 100 took 54.858s\n",
      "  training loss (in-iteration): \t0.002609\n",
      "Epoch 78 of 100 took 68.903s\n",
      "  training loss (in-iteration): \t0.002613\n",
      "Epoch 79 of 100 took 88.563s\n",
      "  training loss (in-iteration): \t0.002580\n",
      "Epoch 80 of 100 took 85.423s\n",
      "  training loss (in-iteration): \t0.002532\n",
      "Epoch 81 of 100 took 75.937s\n",
      "  training loss (in-iteration): \t0.002484\n",
      "Epoch 82 of 100 took 56.245s\n",
      "  training loss (in-iteration): \t0.002449\n",
      "Epoch 83 of 100 took 55.538s\n",
      "  training loss (in-iteration): \t0.002424\n",
      "Epoch 84 of 100 took 54.329s\n",
      "  training loss (in-iteration): \t0.002406\n",
      "Epoch 85 of 100 took 55.833s\n",
      "  training loss (in-iteration): \t0.002392\n",
      "Epoch 86 of 100 took 55.448s\n",
      "  training loss (in-iteration): \t0.002388\n",
      "Epoch 87 of 100 took 51.944s\n",
      "  training loss (in-iteration): \t0.002393\n",
      "Epoch 88 of 100 took 55.431s\n",
      "  training loss (in-iteration): \t0.002407\n",
      "Epoch 89 of 100 took 54.108s\n",
      "  training loss (in-iteration): \t0.002426\n",
      "Epoch 90 of 100 took 54.693s\n",
      "  training loss (in-iteration): \t0.002422\n",
      "Epoch 91 of 100 took 55.121s\n",
      "  training loss (in-iteration): \t0.002407\n",
      "Epoch 92 of 100 took 59.601s\n",
      "  training loss (in-iteration): \t0.002388\n",
      "Epoch 93 of 100 took 75.096s\n",
      "  training loss (in-iteration): \t0.002367\n",
      "Epoch 94 of 100 took 80.708s\n",
      "  training loss (in-iteration): \t0.002352\n",
      "Epoch 95 of 100 took 79.466s\n",
      "  training loss (in-iteration): \t0.002353\n",
      "Epoch 96 of 100 took 58.461s\n",
      "  training loss (in-iteration): \t0.002359\n",
      "Epoch 97 of 100 took 55.495s\n",
      "  training loss (in-iteration): \t0.002346\n",
      "Epoch 98 of 100 took 55.904s\n",
      "  training loss (in-iteration): \t0.002331\n",
      "Epoch 99 of 100 took 54.791s\n",
      "  training loss (in-iteration): \t0.002325\n",
      "Epoch 100 of 100 took 53.233s\n",
      "  training loss (in-iteration): \t0.002330\n"
     ]
    }
   ],
   "source": [
    "train_group4_network(net8_group4, criterion, optimizer, mask_input_1, mask_output_3,\n",
    "#                      shape_input=(batch_size, 3, dim_x, dim_x),\n",
    "              shape_output=(batch_size, 3, int(dim_x / 2), int(dim_x / 2)),\n",
    "              num_epochs=100\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 1 took 51.362s\n",
      "  training loss (in-iteration): \t0.002350\n"
     ]
    }
   ],
   "source": [
    "train_group4_network(net8_group4, criterion, optimizer, mask_input_1, mask_output_3,\n",
    "#                      shape_input=(batch_size, 3, dim_x, dim_x),\n",
    "              shape_output=(batch_size, 3, int(dim_x / 2), int(dim_x / 2)),\n",
    "              num_epochs=1\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koloskov/anaconda3/lib/python3.6/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type Net8Group4. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(net8_group4, \"net8.group4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACxCAYAAADwMnaUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n41+YkHFpcQjEuwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2748111f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_batch_input = X_batch[:, 0].clone()\n",
    "X_batch_input[(~mask_input_3).nonzero()] = 0\n",
    "X_batch_input = Variable(X_batch_input).cuda()\n",
    "plot_gallery(X_batch_input.cpu().data, 8, 8, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_group_1 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(dim_x):\n",
    "            for j in range(dim_x):\n",
    "                if i % 2 == 0 and j % 2 == 0:\n",
    "                    mask_group_1[m][n][i][j] = True\n",
    "\n",
    "mask_group_2 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(dim_x):\n",
    "            for j in range(dim_x):\n",
    "                if i % 2 == 0 and j % 2 == 1:\n",
    "                    mask_group_2[m][n][i][j] = True\n",
    "\n",
    "mask_group_3 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(dim_x):\n",
    "            for j in range(dim_x):\n",
    "                if i % 2 == 1 and j % 2 == 0:\n",
    "                    mask_group_3[m][n][i][j] = True\n",
    "\n",
    "mask_group_4 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(dim_x):\n",
    "            for j in range(dim_x):\n",
    "                if i % 2 == 1 and j % 2 == 1:\n",
    "                    mask_group_4[m][n][i][j] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_input_into_image_8(X_batch):\n",
    "    X_batch_input = X_batch[:, 0].clone()\n",
    "    X_batch_input = X_batch_input[mask_input_1.nonzero()].view((batch_size, 3, int(dim_x / 2), int(dim_x / 2)))\n",
    "\n",
    "    y_batch_output = y_batch[:, 1].clone()\n",
    "    y_batch_output = y_batch_output[mask_input_1.nonzero()].view((batch_size, 3, int(dim_x / 2), int(dim_x / 2)))\n",
    "\n",
    "    X_batch_input = Variable(convert_input_into_image_4(X_batch_input, y_batch_output)).cuda()\n",
    "    \n",
    "    group_1 = X_batch_input.cpu().data\n",
    "    \n",
    "    group_2 = net8_group2(X_batch_input,\n",
    "                 keypoints=autoencoder_stickmans_8(Variable(y_batch[:, 1]).cuda())[1],\n",
    "                 embeddings=autoencoder_people_8(Variable(X_batch[:, 0]).cuda())[1]).cpu().data\n",
    "    \n",
    "    X_cur_input = torch.zeros((batch_size, 3, int(dim_x / 2), dim_x)).float()\n",
    "    X_cur_input[mask_first_part.nonzero()] = group_1.view(-1).float()\n",
    "    X_cur_input[mask_second_part.nonzero()] = group_2.view(-1).float()\n",
    "    group_3 = net8_group3(Variable(X_cur_input).cuda(),\n",
    "             keypoints=autoencoder_stickmans_8(Variable(y_batch[:, 1]).cuda())[1],\n",
    "             embeddings=autoencoder_people_8(Variable(X_batch[:, 0]).cuda())[1]).cpu().data\n",
    "    \n",
    "    X_cur_input = torch.zeros((batch_size, 3, dim_x, dim_x)).float()\n",
    "    X_cur_input[mask8_group_1.nonzero()] = group_1.view(-1).float()\n",
    "    X_cur_input[mask8_group_2.nonzero()] = group_2.view(-1).float()\n",
    "    X_cur_input[mask8_group_3.nonzero()] = group_3.view(-1).float()\n",
    "    \n",
    "    group_4 = net8_group4(Variable(X_cur_input).cuda(),\n",
    "                         keypoints=autoencoder_stickmans_8(Variable(y_batch[:, 1]).cuda())[1],\n",
    "                         embeddings=autoencoder_people_8(Variable(X_batch[:, 0]).cuda())[1]).cpu().data\n",
    "    \n",
    "    final_image = torch.zeros_like(X_batch[:, 1]).float()\n",
    "    final_image[mask_group_1.nonzero()] = group_1.view(-1).float()\n",
    "    final_image[mask_output_1.nonzero()] = group_2.view(-1).float()\n",
    "    final_image[mask_output_2.nonzero()] = group_3.view(-1).float()\n",
    "    final_image[mask_output_3.nonzero()] = group_4.view(-1).float()\n",
    "    \n",
    "    plot_gallery(X_batch[:, 0], 8, 8, 1, 3)\n",
    "    plot_gallery(X_batch[:, 1], 8, 8, 1, 3)\n",
    "    plot_gallery(final_image, 8, 8, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (X_batch, y_batch) in enumerate(train_loader):\n",
    "    if i == 15:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACxCAYAAADwMnaUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3ad8579470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACxCAYAAADwMnaUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3ad80e34e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACxCAYAAADwMnaUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6TtxFPOOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3ac3011588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "convert_input_into_image_8(X_batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
