{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "from loader import get_train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dimZ = 256\n",
    "\n",
    "class Autoencoder8(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder8, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=2, padding=0),\n",
    "#             nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=2, padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=2, padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 16, kernel_size=2, padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(16, 16, 2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
    "            nn.ConvTranspose2d(16, 16, 2, stride=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 3, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent_code = self.encoder(x)\n",
    "        reconstruction = self.decoder(latent_code)\n",
    "        return reconstruction, latent_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create MSE loss function\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "autoencoder = Autoencoder8().cuda()\n",
    "\n",
    "# Use Adam optimizer\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_train_loader(\"../deepfashion/index.p\", batch_size=64, resize_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 100 took 61.297s\n",
      "  training loss (in-iteration): \t0.001223\n",
      "  validation loss: \t\t\t0.001159\n",
      "Epoch 2 of 100 took 61.529s\n",
      "  training loss (in-iteration): \t0.001213\n",
      "  validation loss: \t\t\t0.001160\n"
     ]
    }
   ],
   "source": [
    "# Train your autoencoder\n",
    "# Visualize progress in reconstruction and loss decay\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "reconstructed_pictures = []\n",
    "\n",
    "import time\n",
    "num_epochs = 100 # total amount of full passes over training data\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    start_time = time.time()\n",
    "    autoencoder.train(True) # enable dropout / batch_norm training behavior\n",
    "    i = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        i += 1\n",
    "        # train on batch\n",
    "        X_batch_0 = torch.FloatTensor(X_batch[:, 0])\n",
    "        X_batch_0 = Variable(X_batch_0).cuda()\n",
    "#         X_batch = Variable(X_batch)\n",
    "#         y_batch = Variable(y_batch)\n",
    "        output_img, _ = autoencoder(X_batch_0)\n",
    "        loss = criterion(output_img, X_batch_0)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.append(loss.cpu().data.numpy()[0])\n",
    "#         train_loss.append(loss.data.numpy())\n",
    "        \n",
    "        X_batch_1 = torch.FloatTensor(X_batch[:, 1])\n",
    "        X_batch_1 = Variable(X_batch_1).cuda()\n",
    "#         X_batch = Variable(X_batch)\n",
    "#         y_batch = Variable(y_batch)\n",
    "        output_img, _ = autoencoder(X_batch_1)\n",
    "        loss = criterion(output_img, X_batch_1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.append(loss.cpu().data.numpy()[0])\n",
    "#         train_loss.append(loss.data.numpy())\n",
    "#         print(i, \":\", loss.data.cpu().numpy()[0], end=\", \")\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    autoencoder.train(False) # disable dropout / use averages for batch_norm\n",
    "    for X_batch, y_batch in val_loader:\n",
    "        X_batch_0 = Variable(X_batch[:, 0]).cuda()\n",
    "        output_img, _ = autoencoder(X_batch_0)\n",
    "        val_loss.append(criterion(output_img, X_batch_0).cpu().data.numpy()[0])\n",
    "        X_batch_1 = Variable(X_batch[:, 1]).cuda()\n",
    "        output_img, _ = autoencoder(X_batch_1)\n",
    "        val_loss.append(criterion(output_img, X_batch_1).cpu().data.numpy()[0])\n",
    "#         val_loss.append(criterion(output_img, X_batch).data.numpy())\n",
    "#     if epoch % 16 == 0:\n",
    "#         X_batch = Variable(torch.FloatTensor(np.array([X_val[247]]))).cuda()\n",
    "#         output_img, _ = autoencoder(X_batch)\n",
    "#         # reconstructed_pictures.append(output_img.cpu().data.numpy()[0])\n",
    "#         reconstructed_pictures.append(output_img.data.numpy())\n",
    "    # Then we print the results for this epoch:\n",
    "    print \n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
    "        np.mean(train_loss[-2 * len(train_loader):])))\n",
    "    print(\"  validation loss: \\t\\t\\t{:.6f}\".format(\n",
    "        np.mean(val_loss[-2 * len(val_loader):])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_gallery(images, h, w, n_row=3, n_col=6):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    scale_const = 1.2\n",
    "    plt.figure(figsize=(3 / scale_const * n_col, 3.4 / scale_const * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].numpy().transpose(1,2,0), cmap=plt.cm.gray, vmin=-1, vmax=1, interpolation='nearest')\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_gallery(X_batch[:3, 1], 16, 16, n_row=1, n_col=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_gallery(X_batch[:3, 0], 16, 16, n_row=1, n_col=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_gallery(autoencoder(Variable(X_batch[:3, 1]).cuda())[0].cpu().data, 16, 16, n_row=1, n_col=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.save(autoencoder, \"autoencoder.people.8.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train stickmans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create MSE loss function\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "autoencoder = Autoencoder8().cuda()\n",
    "\n",
    "# Use Adam optimizer\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 1 took 60.342s\n",
      "  training loss (in-iteration): \t0.000253\n",
      "  validation loss: \t\t\t0.000271\n"
     ]
    }
   ],
   "source": [
    "# Train your autoencoder\n",
    "# Visualize progress in reconstruction and loss decay\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "reconstructed_pictures = []\n",
    "\n",
    "import time\n",
    "num_epochs = 1 # total amount of full passes over training data\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    start_time = time.time()\n",
    "    autoencoder.train(True) # enable dropout / batch_norm training behavior\n",
    "    i = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        i += 1\n",
    "        # train on batch\n",
    "        X_batch_0 = torch.FloatTensor(y_batch[:, 0])\n",
    "        X_batch_0 = Variable(X_batch_0).cuda()\n",
    "#         X_batch = Variable(X_batch)\n",
    "#         y_batch = Variable(y_batch)\n",
    "        output_img, _ = autoencoder(X_batch_0)\n",
    "        loss = criterion(output_img, X_batch_0)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.append(loss.cpu().data.numpy()[0])\n",
    "#         train_loss.append(loss.data.numpy())\n",
    "        \n",
    "        X_batch_1 = torch.FloatTensor(y_batch[:, 1])\n",
    "        X_batch_1 = Variable(X_batch_1).cuda()\n",
    "#         X_batch = Variable(X_batch)\n",
    "#         y_batch = Variable(y_batch)\n",
    "        output_img, _ = autoencoder(X_batch_1)\n",
    "        loss = criterion(output_img, X_batch_1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.append(loss.cpu().data.numpy()[0])\n",
    "#         train_loss.append(loss.data.numpy())\n",
    "#         print(i, \":\", loss.data.cpu().numpy()[0], end=\", \")\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    autoencoder.train(False) # disable dropout / use averages for batch_norm\n",
    "    for X_batch, y_batch in val_loader:\n",
    "        X_batch_0 = Variable(y_batch[:, 0]).cuda()\n",
    "        output_img, _ = autoencoder(X_batch_0)\n",
    "        val_loss.append(criterion(output_img, X_batch_0).cpu().data.numpy()[0])\n",
    "        X_batch_1 = Variable(y_batch[:, 1]).cuda()\n",
    "        output_img, _ = autoencoder(X_batch_1)\n",
    "        val_loss.append(criterion(output_img, X_batch_1).cpu().data.numpy()[0])\n",
    "#         val_loss.append(criterion(output_img, X_batch).data.numpy())\n",
    "#     if epoch % 16 == 0:\n",
    "#         X_batch = Variable(torch.FloatTensor(np.array([X_val[247]]))).cuda()\n",
    "#         output_img, _ = autoencoder(X_batch)\n",
    "#         # reconstructed_pictures.append(output_img.cpu().data.numpy()[0])\n",
    "#         reconstructed_pictures.append(output_img.data.numpy())\n",
    "    # Then we print the results for this epoch:\n",
    "    print \n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
    "        np.mean(train_loss[-2 * len(train_loader):])))\n",
    "    print(\"  validation loss: \\t\\t\\t{:.6f}\".format(\n",
    "        np.mean(val_loss[-2 * len(val_loader):])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(autoencoder, \"autoencoder.stickmen.8.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_gallery(y_batch[:3, 1], image_h, image_w, n_row=1, n_col=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_gallery(autoencoder(Variable(y_batch[:3, 1]).cuda())[0].cpu().data, image_h, image_w, n_row=1, n_col=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
