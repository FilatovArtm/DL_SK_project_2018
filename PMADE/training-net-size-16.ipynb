{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "from loader import get_train_loader\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from networks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder_people_4 = torch.load('autoencoder.people.4.pt')\n",
    "autoencoder_stickmans_4 = torch.load('autoencoder.stickmen.4.pt')\n",
    "autoencoder_people_8 = torch.load('autoencoder.people.8.pt')\n",
    "autoencoder_stickmans_8 = torch.load('autoencoder.stickmen.8.pt')\n",
    "autoencoder_people_16 = torch.load('autoencoder.people.16.pt')\n",
    "autoencoder_stickmans_16 = torch.load('autoencoder.stickmen.16.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "mask4_group_1 = np.zeros((batch_size, 3, 8, 8)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(8):\n",
    "            for j in range(8):\n",
    "                if i % 2 == 0 and j % 2 == 0:\n",
    "                    mask4_group_1[m][n][i][j] = True\n",
    "\n",
    "mask4_group_2 = np.zeros((batch_size, 3, 8, 8)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(8):\n",
    "            for j in range(8):\n",
    "                if i % 2 == 0 and j % 2 == 1:\n",
    "                    mask4_group_2[m][n][i][j] = True\n",
    "\n",
    "mask4_group_3 = np.zeros((batch_size, 3, 8, 8)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(8):\n",
    "            for j in range(8):\n",
    "                if i % 2 == 1 and j % 2 == 0:\n",
    "                    mask4_group_3[m][n][i][j] = True\n",
    "\n",
    "mask4_group_4 = np.zeros((batch_size, 3, 8, 8)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(8):\n",
    "            for j in range(8):\n",
    "                if i % 2 == 1 and j % 2 == 1:\n",
    "                    mask4_group_4[m][n][i][j] = True\n",
    "                    \n",
    "                    \n",
    "\n",
    "mask8_group_1 = np.zeros((batch_size, 3, 16, 16)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(16):\n",
    "            for j in range(16):\n",
    "                if i % 2 == 0 and j % 2 == 0:\n",
    "                    mask8_group_1[m][n][i][j] = True\n",
    "\n",
    "mask8_group_2 = np.zeros((batch_size, 3, 16, 16)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(16):\n",
    "            for j in range(16):\n",
    "                if i % 2 == 0 and j % 2 == 1:\n",
    "                    mask8_group_2[m][n][i][j] = True\n",
    "\n",
    "mask8_group_3 = np.zeros((batch_size, 3, 16, 16)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(16):\n",
    "            for j in range(16):\n",
    "                if i % 2 == 1 and j % 2 == 0:\n",
    "                    mask8_group_3[m][n][i][j] = True\n",
    "\n",
    "mask8_group_4 = np.zeros((batch_size, 3, 16, 16)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(16):\n",
    "            for j in range(16):\n",
    "                if i % 2 == 1 and j % 2 == 1:\n",
    "                    mask8_group_4[m][n][i][j] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net4_group2 = torch.load(\"net4.group2.pt\")\n",
    "net4_group3 = torch.load(\"net4.group3.pt\")\n",
    "net4_group4 = torch.load(\"net4.group4.pt\")\n",
    "\n",
    "net8_group2 = torch.load(\"net8.group2.pt\")\n",
    "net8_group3 = torch.load(\"net8.group3.pt\")\n",
    "net8_group4 = torch.load(\"net8.group4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_input_into_image_4(X_batch_input_initial, y_batch_output, is_plot=False):\n",
    "    X_batch_input = X_batch_input_initial.clone()\n",
    "    X_batch_input = X_batch_input[mask4_group_1.nonzero()].view((batch_size, 3, 4, 4))\n",
    "    X_batch_input = Variable(X_batch_input).cuda()\n",
    "    \n",
    "    group_1 = X_batch_input.clone()\n",
    "    group_2 = net4_group2(X_batch_input,\n",
    "                 keypoints=autoencoder_stickmans_4(Variable(y_batch_output).cuda())[1],\n",
    "                 embeddings=autoencoder_people_4(Variable(X_batch_input_initial).cuda())[1]).cpu().data\n",
    "    \n",
    "    X_batch_input = X_batch_input_initial.clone()\n",
    "    X_batch_input = X_batch_input[(mask4_group_1 + mask4_group_2).nonzero()].view((batch_size, 3, 4, 8))\n",
    "    X_batch_input = Variable(X_batch_input).cuda()\n",
    "    \n",
    "    group_3 = net4_group3(X_batch_input,\n",
    "                 keypoints=autoencoder_stickmans_4(Variable(y_batch_output).cuda())[1],\n",
    "                 embeddings=autoencoder_people_4(Variable(X_batch_input_initial).cuda())[1]).cpu().data\n",
    "    \n",
    "    X_batch_input = X_batch_input_initial.clone()\n",
    "    X_batch_input[(mask4_group_4).nonzero()] = 0\n",
    "    X_batch_input = Variable(X_batch_input).cuda()\n",
    "    \n",
    "    group_4 = net4_group4(X_batch_input,\n",
    "                 keypoints=autoencoder_stickmans_4(Variable(y_batch_output).cuda())[1],\n",
    "                 embeddings=autoencoder_people_4(Variable(X_batch_input_initial).cuda())[1]).cpu().data\n",
    "    \n",
    "    final_image = torch.zeros_like(X_batch_input).cpu().data.float()\n",
    "    final_image[mask4_group_1.nonzero()] = group_1.view(-1).cpu().data.float()\n",
    "    final_image[mask4_group_2.nonzero()] = group_2.view(-1).float()\n",
    "    final_image[mask4_group_3.nonzero()] = group_3.view(-1).float()\n",
    "    final_image[mask4_group_4.nonzero()] = group_4.view(-1).float()\n",
    "#     if is_plot:\n",
    "#         plot_gallery(X_batch[:, 1], 8, 8, 1, 3)\n",
    "#         plot_gallery(final_image, 8, 8, 1, 3)\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_first_part_8 = np.zeros((batch_size, 3, 8, 16)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(8):\n",
    "            for j in range(16):\n",
    "                if j % 2 == 0:\n",
    "                    mask_first_part_8[m][n][i][j] = True\n",
    "mask_second_part_8 = np.zeros((batch_size, 3, 8, 16)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(8):\n",
    "            for j in range(16):\n",
    "                if j % 2 == 1:\n",
    "                    mask_second_part_8[m][n][i][j] = True\n",
    "\n",
    "def convert_input_into_image_8(X_batch_initial_input, y_batch_initial_output):\n",
    "    X_batch_input = X_batch_initial_input.clone()\n",
    "    X_batch_input = X_batch_input[mask8_group_1.nonzero()].view((batch_size, 3, 8, 8))\n",
    "\n",
    "    y_batch_output = y_batch_initial_output.clone()\n",
    "    y_batch_output = y_batch_output[mask8_group_1.nonzero()].view((batch_size, 3, 8, 8))\n",
    "\n",
    "    X_batch_input = convert_input_into_image_4(X_batch_input, y_batch_output)\n",
    "    \n",
    "    group_1 = X_batch_input\n",
    "    \n",
    "    group_2 = net8_group2(Variable(X_batch_input).cuda(),\n",
    "                 keypoints=autoencoder_stickmans_8(Variable(y_batch_initial_output).cuda())[1],\n",
    "                 embeddings=autoencoder_people_8(Variable(X_batch_initial_input).cuda())[1]).cpu().data\n",
    "    \n",
    "    X_cur_input = torch.zeros((batch_size, 3, 8, 16)).float()\n",
    "    X_cur_input[mask_first_part_8.nonzero()] = group_1.view(-1).float()\n",
    "    X_cur_input[mask_second_part_8.nonzero()] = group_2.view(-1).float()\n",
    "    group_3 = net8_group3(Variable(X_cur_input).cuda(),\n",
    "             keypoints=autoencoder_stickmans_8(Variable(y_batch_initial_output).cuda())[1],\n",
    "             embeddings=autoencoder_people_8(Variable(X_batch_initial_input).cuda())[1]).cpu().data\n",
    "    \n",
    "    X_cur_input = torch.zeros((batch_size, 3, 16, 16)).float()\n",
    "    X_cur_input[mask8_group_1.nonzero()] = group_1.view(-1).float()\n",
    "    X_cur_input[mask8_group_2.nonzero()] = group_2.view(-1).float()\n",
    "    X_cur_input[mask8_group_3.nonzero()] = group_3.view(-1).float()\n",
    "    \n",
    "    group_4 = net8_group4(Variable(X_cur_input).cuda(),\n",
    "                         keypoints=autoencoder_stickmans_8(Variable(y_batch_initial_output).cuda())[1],\n",
    "                         embeddings=autoencoder_people_8(Variable(X_batch_initial_input).cuda())[1]).cpu().data\n",
    "    \n",
    "    final_image = torch.zeros_like(y_batch_initial_output).float()\n",
    "    final_image[mask8_group_1.nonzero()] = group_1.view(-1).float()\n",
    "    final_image[mask8_group_2.nonzero()] = group_2.view(-1).float()\n",
    "    final_image[mask8_group_3.nonzero()] = group_3.view(-1).float()\n",
    "    final_image[mask8_group_4.nonzero()] = group_4.view(-1).float()\n",
    "    \n",
    "#     plot_gallery(X_batch[:, 0], 8, 8, 1, 3)\n",
    "#     plot_gallery(X_batch[:, 1], 8, 8, 1, 3)\n",
    "#     plot_gallery(final_image, 8, 8, 1, 3)\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim_x = 32\n",
    "batch_size = 64\n",
    "train_loader, val_loader = get_train_loader(\"../deepfashion/index.p\", batch_size=batch_size, resize_size=dim_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net16Group2(nn.Module):\n",
    "    \"\"\"\n",
    "        Network for predictions group 2 images based on group 1.\n",
    "        input size: 4x4\n",
    "        output size: 4x4\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layers=[1], bottelneck_size=32):\n",
    "        super(Net16Group2, self).__init__()\n",
    "        \n",
    "        self.first_part = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=2, padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.up_1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(96, 64, 2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv_1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv_2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), stride=1, padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, kernel_size=(2, 2), stride=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, keypoints, embeddings):\n",
    "        x = self.first_part(x)\n",
    "        x = torch.cat((x, keypoints, embeddings), dim=1)\n",
    "        x = self.up_1(x)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_input_1 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(dim_x):\n",
    "            for j in range(dim_x):\n",
    "                if i % 2 == 0 and j % 2 ==0:\n",
    "                    mask_input_1[m][n][i][j] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_output_1 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(dim_x):\n",
    "            for j in range(dim_x):\n",
    "                if i % 2 == 0 and j % 2 == 1:\n",
    "                    mask_output_1[m][n][i][j] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "net16_group2 = Net16Group2().cuda()\n",
    "optimizer = optim.Adam(net16_group2.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_network(net, criterion, optimizer, mask_input, mask_output, shape_input, shape_output, num_epochs):\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        net.train(True)\n",
    "        i = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            i += 1\n",
    "            if X_batch.shape[0] != batch_size:\n",
    "                continue\n",
    "            X_batch_input = X_batch[:, 0]\n",
    "            X_batch_input = X_batch_input[mask_input.nonzero()].view(shape_input)\n",
    "            \n",
    "            y_batch_output = y_batch[:, 1]\n",
    "            y_batch_output = y_batch_output[mask_input.nonzero()].view(shape_input)\n",
    "            \n",
    "            X_batch_input = Variable(convert_input_into_image_8(X_batch_input, y_batch_output)).cuda()\n",
    "\n",
    "            X_batch_output = X_batch[:, 1]\n",
    "            X_batch_output = X_batch_output[mask_output.nonzero()].view(shape_output)\n",
    "            X_batch_output = Variable(X_batch_output).cuda()\n",
    "\n",
    "            output_img = net(X_batch_input,\n",
    "                                     keypoints=autoencoder_stickmans_16(Variable(y_batch[:, 1]).cuda())[1],\n",
    "                                     embeddings=autoencoder_people_16(Variable(X_batch[:, 0]).cuda())[1])\n",
    "            loss = criterion(output_img, X_batch_output)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.append(loss.cpu().data.numpy()[0])\n",
    "\n",
    "        # And a full pass over the validation data:\n",
    "    #     autoencoder.train(False) # disable dropout / use averages for batch_norm\n",
    "    #     for X_batch, y_batch in val_loader:\n",
    "    #         X_batch_0 = Variable(y_batch[:, 0]).cuda()\n",
    "    #         output_img, _ = autoencoder(X_batch_0)\n",
    "    #         val_loss.append(criterion(output_img, X_batch_0).cpu().data.numpy()[0])\n",
    "    #         X_batch_1 = Variable(y_batch[:, 1]).cuda()\n",
    "    #         output_img, _ = autoencoder(X_batch_1)\n",
    "    #         val_loss.append(criterion(output_img, X_batch_1).cpu().data.numpy()[0])\n",
    "\n",
    "        print \n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
    "            np.mean(train_loss[-2 * len(train_loader):])))\n",
    "    #     print(\"  validation loss: \\t\\t\\t{:.6f}\".format(\n",
    "    #         np.mean(val_loss[-2 * len(val_loader):])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 200 took 60.222s\n",
      "  training loss (in-iteration): \t0.010461\n",
      "Epoch 2 of 200 took 59.364s\n",
      "  training loss (in-iteration): \t0.010392\n",
      "Epoch 3 of 200 took 67.030s\n",
      "  training loss (in-iteration): \t0.010266\n",
      "Epoch 4 of 200 took 91.134s\n",
      "  training loss (in-iteration): \t0.010150\n",
      "Epoch 5 of 200 took 83.484s\n",
      "  training loss (in-iteration): \t0.010032\n",
      "Epoch 6 of 200 took 76.592s\n",
      "  training loss (in-iteration): \t0.009913\n",
      "Epoch 7 of 200 took 60.543s\n",
      "  training loss (in-iteration): \t0.009815\n",
      "Epoch 8 of 200 took 59.300s\n",
      "  training loss (in-iteration): \t0.009723\n",
      "Epoch 9 of 200 took 60.387s\n",
      "  training loss (in-iteration): \t0.009619\n",
      "Epoch 10 of 200 took 59.711s\n",
      "  training loss (in-iteration): \t0.009520\n",
      "Epoch 11 of 200 took 61.373s\n",
      "  training loss (in-iteration): \t0.009436\n",
      "Epoch 12 of 200 took 61.270s\n",
      "  training loss (in-iteration): \t0.009354\n",
      "Epoch 13 of 200 took 62.042s\n",
      "  training loss (in-iteration): \t0.009271\n",
      "Epoch 14 of 200 took 59.564s\n",
      "  training loss (in-iteration): \t0.009178\n",
      "Epoch 15 of 200 took 59.993s\n",
      "  training loss (in-iteration): \t0.009089\n",
      "Epoch 16 of 200 took 61.784s\n",
      "  training loss (in-iteration): \t0.009013\n",
      "Epoch 17 of 200 took 60.135s\n",
      "  training loss (in-iteration): \t0.008945\n",
      "Epoch 18 of 200 took 58.477s\n",
      "  training loss (in-iteration): \t0.008881\n",
      "Epoch 19 of 200 took 61.301s\n",
      "  training loss (in-iteration): \t0.008828\n",
      "Epoch 20 of 200 took 61.038s\n",
      "  training loss (in-iteration): \t0.008772\n",
      "Epoch 21 of 200 took 58.817s\n",
      "  training loss (in-iteration): \t0.008684\n",
      "Epoch 22 of 200 took 59.792s\n",
      "  training loss (in-iteration): \t0.008593\n"
     ]
    }
   ],
   "source": [
    "train_network(net16_group2, criterion, optimizer, mask_input_1, mask_output_1,\n",
    "              shape_input=(batch_size, 3, int(dim_x / 2), int(dim_x / 2)),\n",
    "              shape_output=(batch_size, 3, int(dim_x / 2), int(dim_x / 2)),\n",
    "              num_epochs=200\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 1 took 62.069s\n",
      "  training loss (in-iteration): \t0.005138\n"
     ]
    }
   ],
   "source": [
    "train_network(net16_group2, criterion, optimizer, mask_input_1, mask_output_1,\n",
    "              shape_input=(batch_size, 3, int(dim_x / 2), int(dim_x / 2)),\n",
    "              shape_output=(batch_size, 3, int(dim_x / 2), int(dim_x / 2)),\n",
    "              num_epochs=1\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koloskov/anaconda3/lib/python3.6/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type Net16Group2. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(net16_group2, \"net16.group2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# net8_group2 = torch.load(\"net16.group2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for X_batch, y_batch in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_batch_input = X_batch[:, 0]\n",
    "X_batch_input = X_batch_input[mask_input_1.nonzero()].view((batch_size, 3, int(dim_x / 2), int(dim_x / 2)))\n",
    "X_batch_input = Variable(X_batch_input).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACxCAYAAADwMnaUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9b003b1278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_gallery(X_batch_input.cpu().data, 8, 8, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACxCAYAAADwMnaUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBABoQ5gAAG38C48NpjE117lTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9b00991358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_batch_input = X_batch[:, 0]\n",
    "X_batch_input = X_batch_input[mask_input_1.nonzero()].view((batch_size, 3, int(dim_x / 2), int(dim_x / 2)))\n",
    "\n",
    "y_batch_output = y_batch[:, 1]\n",
    "y_batch_output = y_batch_output[mask_input_1.nonzero()].view((batch_size, 3, int(dim_x / 2), int(dim_x / 2)))\n",
    "\n",
    "X_batch_input = Variable(convert_input_into_image_4(X_batch_input, y_batch_output)).cuda()\n",
    "\n",
    "X_batch_output = X_batch[:, 1]\n",
    "X_batch_output = X_batch_output[mask_output_1.nonzero()].view((batch_size, 3, int(dim_x / 2), int(dim_x / 2)))\n",
    "X_batch_output = Variable(X_batch_output).cuda()\n",
    "plot_gallery(net8_group2(X_batch_input,\n",
    "                 keypoints=autoencoder_stickmans_8(Variable(y_batch[:, 1]).cuda())[1],\n",
    "                 embeddings=autoencoder_people_8(Variable(X_batch[:, 0]).cuda())[1]).cpu().data,\n",
    "             8, 8, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_batch_output = X_batch[:, 1]\n",
    "X_batch_output = X_batch_output[mask_output_1.nonzero()].view((batch_size, 3, int(dim_x / 2), int(dim_x / 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACxCAYAAADwMnaUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9b00160cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_gallery(X_batch_output, 8, 8, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net16Group3(nn.Module):\n",
    "    \"\"\"\n",
    "        Network for predictions group 2 images based on group 1.\n",
    "        input size: 4x4\n",
    "        output size: 4x4\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layers=[1], bottelneck_size=32):\n",
    "        super(Net16Group3, self).__init__()\n",
    "        \n",
    "        self.first_part = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=2, padding=0),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=(1, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(1, 3)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(1, 3)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(1, 3)),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.up_1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(96, 64, 2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv_1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv_2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), stride=1, padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, kernel_size=(2, 2), stride=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, keypoints, embeddings):\n",
    "        x = self.first_part(x)\n",
    "#         print(x.shape)\n",
    "        x = torch.cat((x, keypoints, embeddings), dim=1)\n",
    "        x = self.up_1(x)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_network_group_3(net, criterion, optimizer, mask_input, mask_output, shape_input, shape_output, num_epochs):\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    \n",
    "    mask_first_part = np.zeros((batch_size, 3, int(dim_x / 2), dim_x)).astype(bool)\n",
    "    for m in range(batch_size):\n",
    "        for n in range(3):\n",
    "            for i in range(int(dim_x/2)):\n",
    "                for j in range(dim_x):\n",
    "                    if j % 2 == 0:\n",
    "                        mask_first_part[m][n][i][j] = True\n",
    "    mask_second_part = np.zeros((batch_size, 3, int(dim_x / 2), dim_x)).astype(bool)\n",
    "    for m in range(batch_size):\n",
    "        for n in range(3):\n",
    "            for i in range(int(dim_x/2)):\n",
    "                for j in range(dim_x):\n",
    "                    if j % 2 == 1:\n",
    "                        mask_second_part[m][n][i][j] = True\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        net.train(True)\n",
    "        i = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            i += 1\n",
    "            if X_batch.shape[0] != batch_size:\n",
    "                continue\n",
    "            X_batch_input = X_batch[:, 0]\n",
    "            X_batch_input = X_batch_input[mask_input.nonzero()].view(shape_output)\n",
    "            \n",
    "            y_batch_output = y_batch[:, 1]\n",
    "            y_batch_output = y_batch_output[mask_input.nonzero()].view(shape_output)\n",
    "            \n",
    "            X_batch_input = Variable(convert_input_into_image_8(X_batch_input, y_batch_output)).cuda()\n",
    "            X_batch_group_2 = net16_group2(X_batch_input,\n",
    "                 keypoints=autoencoder_stickmans_16(Variable(y_batch[:, 1]).cuda())[1],\n",
    "                 embeddings=autoencoder_people_16(Variable(X_batch[:, 0]).cuda())[1])\n",
    "#             print(X_batch_input.shape)\n",
    "#             print(X_batch_group_2.shape)\n",
    "            X_cur_input = Variable(torch.zeros(shape_input)).cuda().float()\n",
    "            X_cur_input[mask_first_part.nonzero()] = X_batch_input.view(-1).float()\n",
    "            X_cur_input[mask_second_part.nonzero()] = X_batch_group_2.view(-1).float()\n",
    "#             print(X_cur_input.shape)\n",
    "            X_batch_output = X_batch[:, 1]\n",
    "            X_batch_output = X_batch_output[mask_output.nonzero()].view(shape_output)\n",
    "            X_batch_output = Variable(X_batch_output).cuda()\n",
    "\n",
    "            output_img = net(X_cur_input,\n",
    "                                     keypoints=autoencoder_stickmans_16(Variable(y_batch[:, 1]).cuda())[1],\n",
    "                                     embeddings=autoencoder_people_16(Variable(X_batch[:, 0]).cuda())[1])\n",
    "            loss = criterion(output_img, X_batch_output)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.append(loss.cpu().data.numpy()[0])\n",
    "\n",
    "        # And a full pass over the validation data:\n",
    "    #     autoencoder.train(False) # disable dropout / use averages for batch_norm\n",
    "    #     for X_batch, y_batch in val_loader:\n",
    "    #         X_batch_0 = Variable(y_batch[:, 0]).cuda()\n",
    "    #         output_img, _ = autoencoder(X_batch_0)\n",
    "    #         val_loss.append(criterion(output_img, X_batch_0).cpu().data.numpy()[0])\n",
    "    #         X_batch_1 = Variable(y_batch[:, 1]).cuda()\n",
    "    #         output_img, _ = autoencoder(X_batch_1)\n",
    "    #         val_loss.append(criterion(output_img, X_batch_1).cpu().data.numpy()[0])\n",
    "\n",
    "        print \n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
    "            np.mean(train_loss[-2 * len(train_loader):])))\n",
    "    #     print(\"  validation loss: \\t\\t\\t{:.6f}\".format(\n",
    "    #         np.mean(val_loss[-2 * len(val_loader):])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mask_input_2 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "# for m in range(batch_size):\n",
    "#     for n in range(3):\n",
    "#         for i in range(dim_x):\n",
    "#             for j in range(dim_x):\n",
    "#                 if i % 2 == 0:\n",
    "#                     mask_input_2[m][n][i][j] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_output_2 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(dim_x):\n",
    "            for j in range(dim_x):\n",
    "                if i % 2 == 1 and j % 2 == 0:\n",
    "                    mask_output_2[m][n][i][j] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "net16_group3 = Net16Group3().cuda()\n",
    "optimizer = optim.Adam(net16_group3.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 100 took 65.663s\n",
      "  training loss (in-iteration): \t0.023012\n",
      "Epoch 2 of 100 took 67.341s\n",
      "  training loss (in-iteration): \t0.016831\n",
      "Epoch 3 of 100 took 66.272s\n",
      "  training loss (in-iteration): \t0.009960\n",
      "Epoch 4 of 100 took 64.322s\n",
      "  training loss (in-iteration): \t0.008999\n",
      "Epoch 5 of 100 took 69.305s\n",
      "  training loss (in-iteration): \t0.008588\n",
      "Epoch 6 of 100 took 68.688s\n",
      "  training loss (in-iteration): \t0.008323\n",
      "Epoch 7 of 100 took 66.699s\n",
      "  training loss (in-iteration): \t0.008122\n",
      "Epoch 8 of 100 took 67.570s\n",
      "  training loss (in-iteration): \t0.007940\n",
      "Epoch 9 of 100 took 68.324s\n",
      "  training loss (in-iteration): \t0.007783\n",
      "Epoch 10 of 100 took 69.963s\n",
      "  training loss (in-iteration): \t0.007645\n",
      "Epoch 11 of 100 took 67.807s\n",
      "  training loss (in-iteration): \t0.007523\n",
      "Epoch 12 of 100 took 67.325s\n",
      "  training loss (in-iteration): \t0.007422\n",
      "Epoch 13 of 100 took 67.352s\n",
      "  training loss (in-iteration): \t0.007326\n",
      "Epoch 14 of 100 took 67.286s\n",
      "  training loss (in-iteration): \t0.007233\n",
      "Epoch 15 of 100 took 70.280s\n",
      "  training loss (in-iteration): \t0.007152\n",
      "Epoch 16 of 100 took 68.040s\n",
      "  training loss (in-iteration): \t0.007079\n",
      "Epoch 17 of 100 took 66.043s\n",
      "  training loss (in-iteration): \t0.007010\n",
      "Epoch 18 of 100 took 66.157s\n",
      "  training loss (in-iteration): \t0.006954\n",
      "Epoch 19 of 100 took 65.012s\n",
      "  training loss (in-iteration): \t0.006917\n",
      "Epoch 20 of 100 took 66.802s\n",
      "  training loss (in-iteration): \t0.006860\n",
      "Epoch 21 of 100 took 63.130s\n",
      "  training loss (in-iteration): \t0.006780\n",
      "Epoch 22 of 100 took 69.315s\n",
      "  training loss (in-iteration): \t0.006725\n",
      "Epoch 23 of 100 took 73.037s\n",
      "  training loss (in-iteration): \t0.006688\n",
      "Epoch 24 of 100 took 68.601s\n",
      "  training loss (in-iteration): \t0.006628\n",
      "Epoch 25 of 100 took 69.852s\n",
      "  training loss (in-iteration): \t0.006551\n",
      "Epoch 26 of 100 took 69.031s\n",
      "  training loss (in-iteration): \t0.006476\n",
      "Epoch 27 of 100 took 71.130s\n",
      "  training loss (in-iteration): \t0.006414\n",
      "Epoch 28 of 100 took 70.008s\n",
      "  training loss (in-iteration): \t0.006362\n",
      "Epoch 29 of 100 took 69.645s\n",
      "  training loss (in-iteration): \t0.006308\n",
      "Epoch 30 of 100 took 65.651s\n",
      "  training loss (in-iteration): \t0.006258\n",
      "Epoch 31 of 100 took 65.099s\n",
      "  training loss (in-iteration): \t0.006237\n",
      "Epoch 32 of 100 took 66.422s\n",
      "  training loss (in-iteration): \t0.006238\n",
      "Epoch 33 of 100 took 64.154s\n",
      "  training loss (in-iteration): \t0.006236\n",
      "Epoch 34 of 100 took 64.177s\n",
      "  training loss (in-iteration): \t0.006223\n",
      "Epoch 35 of 100 took 65.770s\n",
      "  training loss (in-iteration): \t0.006171\n",
      "Epoch 36 of 100 took 66.916s\n",
      "  training loss (in-iteration): \t0.006102\n",
      "Epoch 37 of 100 took 65.581s\n",
      "  training loss (in-iteration): \t0.006057\n",
      "Epoch 38 of 100 took 67.307s\n",
      "  training loss (in-iteration): \t0.006034\n",
      "Epoch 39 of 100 took 67.087s\n",
      "  training loss (in-iteration): \t0.006006\n",
      "Epoch 40 of 100 took 70.266s\n",
      "  training loss (in-iteration): \t0.005973\n",
      "Epoch 41 of 100 took 69.554s\n",
      "  training loss (in-iteration): \t0.005919\n",
      "Epoch 42 of 100 took 70.517s\n",
      "  training loss (in-iteration): \t0.005838\n",
      "Epoch 43 of 100 took 71.560s\n",
      "  training loss (in-iteration): \t0.005762\n",
      "Epoch 44 of 100 took 68.935s\n",
      "  training loss (in-iteration): \t0.005708\n",
      "Epoch 45 of 100 took 67.374s\n",
      "  training loss (in-iteration): \t0.005681\n",
      "Epoch 46 of 100 took 69.966s\n",
      "  training loss (in-iteration): \t0.005668\n",
      "Epoch 47 of 100 took 69.308s\n",
      "  training loss (in-iteration): \t0.005650\n",
      "Epoch 48 of 100 took 68.103s\n",
      "  training loss (in-iteration): \t0.005638\n",
      "Epoch 49 of 100 took 68.730s\n",
      "  training loss (in-iteration): \t0.005630\n",
      "Epoch 50 of 100 took 65.668s\n",
      "  training loss (in-iteration): \t0.005619\n",
      "Epoch 51 of 100 took 63.415s\n",
      "  training loss (in-iteration): \t0.005604\n",
      "Epoch 52 of 100 took 61.696s\n",
      "  training loss (in-iteration): \t0.005575\n",
      "Epoch 53 of 100 took 64.932s\n",
      "  training loss (in-iteration): \t0.005526\n",
      "Epoch 54 of 100 took 66.331s\n",
      "  training loss (in-iteration): \t0.005460\n",
      "Epoch 55 of 100 took 68.500s\n",
      "  training loss (in-iteration): \t0.005409\n",
      "Epoch 56 of 100 took 66.755s\n",
      "  training loss (in-iteration): \t0.005370\n",
      "Epoch 57 of 100 took 64.477s\n",
      "  training loss (in-iteration): \t0.005330\n",
      "Epoch 58 of 100 took 63.695s\n",
      "  training loss (in-iteration): \t0.005297\n",
      "Epoch 59 of 100 took 65.253s\n",
      "  training loss (in-iteration): \t0.005271\n",
      "Epoch 60 of 100 took 64.964s\n",
      "  training loss (in-iteration): \t0.005252\n",
      "Epoch 61 of 100 took 66.161s\n",
      "  training loss (in-iteration): \t0.005251\n",
      "Epoch 62 of 100 took 63.916s\n",
      "  training loss (in-iteration): \t0.005254\n",
      "Epoch 63 of 100 took 65.959s\n",
      "  training loss (in-iteration): \t0.005243\n",
      "Epoch 64 of 100 took 68.482s\n",
      "  training loss (in-iteration): \t0.005214\n",
      "Epoch 65 of 100 took 70.705s\n",
      "  training loss (in-iteration): \t0.005175\n",
      "Epoch 66 of 100 took 70.552s\n",
      "  training loss (in-iteration): \t0.005139\n",
      "Epoch 67 of 100 took 68.567s\n",
      "  training loss (in-iteration): \t0.005113\n",
      "Epoch 68 of 100 took 68.182s\n",
      "  training loss (in-iteration): \t0.005082\n",
      "Epoch 69 of 100 took 67.087s\n",
      "  training loss (in-iteration): \t0.005059\n",
      "Epoch 70 of 100 took 67.194s\n",
      "  training loss (in-iteration): \t0.005063\n",
      "Epoch 71 of 100 took 68.910s\n",
      "  training loss (in-iteration): \t0.005077\n",
      "Epoch 72 of 100 took 66.527s\n",
      "  training loss (in-iteration): \t0.005087\n",
      "Epoch 73 of 100 took 65.778s\n",
      "  training loss (in-iteration): \t0.005085\n",
      "Epoch 74 of 100 took 66.593s\n",
      "  training loss (in-iteration): \t0.005072\n",
      "Epoch 75 of 100 took 65.585s\n",
      "  training loss (in-iteration): \t0.005056\n",
      "Epoch 76 of 100 took 66.505s\n",
      "  training loss (in-iteration): \t0.005033\n",
      "Epoch 77 of 100 took 69.031s\n",
      "  training loss (in-iteration): \t0.005021\n",
      "Epoch 78 of 100 took 67.540s\n",
      "  training loss (in-iteration): \t0.005022\n",
      "Epoch 79 of 100 took 67.358s\n",
      "  training loss (in-iteration): \t0.005035\n",
      "Epoch 80 of 100 took 68.166s\n",
      "  training loss (in-iteration): \t0.005053\n",
      "Epoch 81 of 100 took 68.587s\n",
      "  training loss (in-iteration): \t0.005041\n",
      "Epoch 82 of 100 took 68.878s\n",
      "  training loss (in-iteration): \t0.004988\n",
      "Epoch 83 of 100 took 66.543s\n",
      "  training loss (in-iteration): \t0.004926\n",
      "Epoch 84 of 100 took 66.656s\n",
      "  training loss (in-iteration): \t0.004869\n",
      "Epoch 85 of 100 took 64.682s\n",
      "  training loss (in-iteration): \t0.004825\n",
      "Epoch 86 of 100 took 65.527s\n",
      "  training loss (in-iteration): \t0.004793\n",
      "Epoch 87 of 100 took 65.115s\n",
      "  training loss (in-iteration): \t0.004764\n",
      "Epoch 88 of 100 took 66.376s\n",
      "  training loss (in-iteration): \t0.004759\n",
      "Epoch 89 of 100 took 66.526s\n",
      "  training loss (in-iteration): \t0.004760\n",
      "Epoch 90 of 100 took 65.592s\n",
      "  training loss (in-iteration): \t0.004747\n",
      "Epoch 91 of 100 took 64.623s\n",
      "  training loss (in-iteration): \t0.004725\n",
      "Epoch 92 of 100 took 65.237s\n",
      "  training loss (in-iteration): \t0.004711\n",
      "Epoch 93 of 100 took 67.260s\n",
      "  training loss (in-iteration): \t0.004703\n",
      "Epoch 94 of 100 took 66.235s\n",
      "  training loss (in-iteration): \t0.004678\n",
      "Epoch 95 of 100 took 67.583s\n",
      "  training loss (in-iteration): \t0.004641\n",
      "Epoch 96 of 100 took 69.043s\n",
      "  training loss (in-iteration): \t0.004615\n",
      "Epoch 97 of 100 took 69.059s\n",
      "  training loss (in-iteration): \t0.004612\n",
      "Epoch 98 of 100 took 68.376s\n",
      "  training loss (in-iteration): \t0.004624\n",
      "Epoch 99 of 100 took 69.687s\n",
      "  training loss (in-iteration): \t0.004645\n",
      "Epoch 100 of 100 took 67.966s\n",
      "  training loss (in-iteration): \t0.004654\n"
     ]
    }
   ],
   "source": [
    "train_network_group_3(net16_group3, criterion, optimizer, mask_input_1, mask_output_2,\n",
    "              shape_input=(batch_size, 3, int(dim_x / 2), int(dim_x)),\n",
    "              shape_output=(batch_size, 3, int(dim_x / 2), int(dim_x / 2)),\n",
    "              num_epochs=100\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koloskov/anaconda3/lib/python3.6/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type Net16Group3. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(net16_group3, \"net16.group3.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAABjCAYAAACvxMuwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCCGEEInhfwAR0jdME359dwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff17580afd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for X_batch, y_batch in train_loader:\n",
    "    break\n",
    "mask_first_part = np.zeros((batch_size, 3, int(dim_x / 2), dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(int(dim_x/2)):\n",
    "            for j in range(dim_x):\n",
    "                if j % 2 == 0:\n",
    "                    mask_first_part[m][n][i][j] = True\n",
    "mask_second_part = np.zeros((batch_size, 3, int(dim_x / 2), dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(int(dim_x/2)):\n",
    "            for j in range(dim_x):\n",
    "                if j % 2 == 1:\n",
    "                    mask_second_part[m][n][i][j] = True\n",
    "\n",
    "X_batch_input = X_batch[:, 0]\n",
    "X_batch_input = X_batch_input[mask_input_1.nonzero()].view((batch_size, 3, int(dim_x / 2), int(dim_x / 2)))\n",
    "y_batch_output = y_batch[:, 1]\n",
    "y_batch_output = y_batch_output[mask_input_1.nonzero()].view((batch_size, 3, int(dim_x / 2), int(dim_x / 2)))\n",
    "\n",
    "X_batch_input = Variable(convert_input_into_image_8(X_batch_input, y_batch_output)).cuda()\n",
    "X_batch_group_2 = net8_group2(X_batch_input,\n",
    "     keypoints=autoencoder_stickmans_8(Variable(y_batch[:, 1]).cuda())[1],\n",
    "     embeddings=autoencoder_people_8(Variable(X_batch[:, 0]).cuda())[1])\n",
    "#             print(X_batch_input.shape)\n",
    "#             print(X_batch_group_2.shape)\n",
    "X_cur_input = Variable(torch.zeros((batch_size, 3, int(dim_x / 2), int(dim_x)))).cuda().float()\n",
    "X_cur_input[mask_first_part.nonzero()] = X_batch_input.view(-1).float()\n",
    "X_cur_input[mask_second_part.nonzero()] = X_batch_group_2.view(-1).float()\n",
    "plot_gallery(X_cur_input.cpu().data, 8, 8, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACxCAYAAADwMnaUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZriCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3ad88efa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_gallery(net8_group3(X_cur_input,\n",
    "                 keypoints=autoencoder_stickmans_8(Variable(y_batch[:, 1]).cuda())[1],\n",
    "                 embeddings=autoencoder_people_8(Variable(X_batch[:, 0]).cuda())[1]).cpu().data,\n",
    "             8, 8, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACxCAYAAADwMnaUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nECYAQBvCBABoQ5gAAG0IEwCgjX8DhQwUTwYGJVQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3ad8884470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_batch_output = X_batch[:, 1]\n",
    "X_batch_output = X_batch_output[mask_output_2.nonzero()].view((batch_size, 3, int(dim_x / 2), int(dim_x / 2)))\n",
    "plot_gallery(X_batch_output, 8, 8, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask16_group_1 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(dim_x):\n",
    "            for j in range(dim_x):\n",
    "                if i % 2 == 0 and j % 2 == 0:\n",
    "                    mask16_group_1[m][n][i][j] = True\n",
    "mask16_group_2 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(dim_x):\n",
    "            for j in range(dim_x):\n",
    "                if i % 2 == 0 and j % 2 == 1:\n",
    "                    mask16_group_2[m][n][i][j] = True\n",
    "\n",
    "mask16_group_3 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(dim_x):\n",
    "            for j in range(dim_x):\n",
    "                if i % 2 == 1 and j % 2 == 0:\n",
    "                    mask16_group_3[m][n][i][j] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_group4_network(net, criterion, optimizer, mask_input, mask_output, shape_output, num_epochs):\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    \n",
    "    mask_first_part = np.zeros((batch_size, 3, int(dim_x / 2), dim_x)).astype(bool)\n",
    "    for m in range(batch_size):\n",
    "        for n in range(3):\n",
    "            for i in range(int(dim_x/2)):\n",
    "                for j in range(dim_x):\n",
    "                    if j % 2 == 0:\n",
    "                        mask_first_part[m][n][i][j] = True\n",
    "    mask_second_part = np.zeros((batch_size, 3, int(dim_x / 2), dim_x)).astype(bool)\n",
    "    for m in range(batch_size):\n",
    "        for n in range(3):\n",
    "            for i in range(int(dim_x/2)):\n",
    "                for j in range(dim_x):\n",
    "                    if j % 2 == 1:\n",
    "                        mask_second_part[m][n][i][j] = True\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        net.train(True)\n",
    "        i = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            i += 1\n",
    "            if X_batch.shape[0] != batch_size:\n",
    "                continue\n",
    "#             X_batch_input = X_batch[:, 0]\n",
    "#             X_batch_input[(~mask_input).nonzero()] = 0\n",
    "#             X_batch_input = Variable(X_batch_input).cuda()\n",
    "\n",
    "#             X_batch_output = X_batch[:, 1]\n",
    "#             X_batch_output = X_batch_output[mask_output.nonzero()].view(shape_output)\n",
    "#             X_batch_output = Variable(X_batch_output).cuda()\n",
    "\n",
    "            X_batch_input = X_batch[:, 0]\n",
    "            X_batch_input = X_batch_input[mask_input.nonzero()].view(shape_output)\n",
    "            \n",
    "            y_batch_output = y_batch[:, 1]\n",
    "            y_batch_output = y_batch_output[mask_input.nonzero()].view(shape_output)\n",
    "            \n",
    "            X_batch_input = Variable(convert_input_into_image_8(X_batch_input, y_batch_output)).cuda()\n",
    "            X_batch_group_2 = net16_group2(X_batch_input,\n",
    "                 keypoints=autoencoder_stickmans_16(Variable(y_batch[:, 1]).cuda())[1],\n",
    "                 embeddings=autoencoder_people_16(Variable(X_batch[:, 0]).cuda())[1])\n",
    "#             print(X_batch_input.shape)\n",
    "            X_cur_input = Variable(torch.zeros((batch_size, 3, int(dim_x / 2), dim_x))).cuda().float()\n",
    "            X_cur_input[mask_first_part.nonzero()] = X_batch_input.view(-1).float()\n",
    "            X_cur_input[mask_second_part.nonzero()] = X_batch_group_2.view(-1).float()\n",
    "            X_batch_group_3 = net16_group3(X_cur_input,\n",
    "                 keypoints=autoencoder_stickmans_16(Variable(y_batch[:, 1]).cuda())[1],\n",
    "                 embeddings=autoencoder_people_16(Variable(X_batch[:, 0]).cuda())[1])\n",
    "#             print(X_cur_input.shape)\n",
    "\n",
    "            X_cur_input = Variable(torch.zeros((batch_size, 3, dim_x, dim_x))).cuda().float()\n",
    "            X_cur_input[mask16_group_1.nonzero()] = X_batch_input.view(-1).float()\n",
    "            X_cur_input[mask16_group_2.nonzero()] = X_batch_group_2.view(-1).float()\n",
    "            X_cur_input[mask16_group_3.nonzero()] = X_batch_group_3.view(-1).float()\n",
    "    \n",
    "            X_batch_output = X_batch[:, 1]\n",
    "            X_batch_output = X_batch_output[mask_output.nonzero()].view(shape_output)\n",
    "            X_batch_output = Variable(X_batch_output).cuda()\n",
    "\n",
    "            output_img = net(X_cur_input,\n",
    "                             keypoints=autoencoder_stickmans_16(Variable(y_batch[:, 1]).cuda())[1],\n",
    "                             embeddings=autoencoder_people_16(Variable(X_batch[:, 0]).cuda())[1])\n",
    "            loss = criterion(output_img, X_batch_output)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.append(loss.cpu().data.numpy()[0])\n",
    "\n",
    "        # And a full pass over the validation data:\n",
    "    #     autoencoder.train(False) # disable dropout / use averages for batch_norm\n",
    "    #     for X_batch, y_batch in val_loader:\n",
    "    #         X_batch_0 = Variable(y_batch[:, 0]).cuda()\n",
    "    #         output_img, _ = autoencoder(X_batch_0)\n",
    "    #         val_loss.append(criterion(output_img, X_batch_0).cpu().data.numpy()[0])\n",
    "    #         X_batch_1 = Variable(y_batch[:, 1]).cuda()\n",
    "    #         output_img, _ = autoencoder(X_batch_1)\n",
    "    #         val_loss.append(criterion(output_img, X_batch_1).cpu().data.numpy()[0])\n",
    "\n",
    "        print \n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
    "            np.mean(train_loss[-2 * len(train_loader):])))\n",
    "    #     print(\"  validation loss: \\t\\t\\t{:.6f}\".format(\n",
    "    #         np.mean(val_loss[-2 * len(val_loader):])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net16Group4(nn.Module):\n",
    "    \"\"\"\n",
    "        Network for predictions group 2 images based on group 1.\n",
    "        input size: 4x4\n",
    "        output size: 4x4\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layers=[1], bottelneck_size=32):\n",
    "        super(Net16Group4, self).__init__()\n",
    "        \n",
    "        self.first_part = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=2, padding=0),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=(3, 3), stride=1, ),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.up_1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(96, 64, 2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv_1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv_2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=(2, 2), stride=1, padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, kernel_size=(2, 2), stride=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, keypoints, embeddings):\n",
    "        x = self.first_part(x)\n",
    "        x = torch.cat((x, keypoints, embeddings), dim=1)\n",
    "        x = self.up_1(x)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mask_input_3 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "# for m in range(batch_size):\n",
    "#     for n in range(3):\n",
    "#         for i in range(dim_x):\n",
    "#             for j in range(dim_x):\n",
    "#                 if i % 2 == 0 or j % 2 == 0:\n",
    "#                     mask_input_3[m][n][i][j] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_output_3 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(dim_x):\n",
    "            for j in range(dim_x):\n",
    "                if i % 2 == 1 and j % 2 == 1:\n",
    "                    mask_output_3[m][n][i][j] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "net16_group4 = Net16Group4().cuda()\n",
    "optimizer = optim.Adam(net16_group4.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 100 took 78.283s\n",
      "  training loss (in-iteration): \t0.023855\n",
      "Epoch 2 of 100 took 79.508s\n",
      "  training loss (in-iteration): \t0.017079\n",
      "Epoch 3 of 100 took 79.943s\n",
      "  training loss (in-iteration): \t0.009701\n",
      "Epoch 4 of 100 took 82.998s\n",
      "  training loss (in-iteration): \t0.008757\n",
      "Epoch 5 of 100 took 77.082s\n",
      "  training loss (in-iteration): \t0.008219\n",
      "Epoch 6 of 100 took 78.603s\n",
      "  training loss (in-iteration): \t0.007857\n",
      "Epoch 7 of 100 took 79.255s\n",
      "  training loss (in-iteration): \t0.007567\n"
     ]
    }
   ],
   "source": [
    "train_group4_network(net16_group4, criterion, optimizer, mask_input_1, mask_output_3,\n",
    "#                      shape_input=(batch_size, 3, dim_x, dim_x),\n",
    "              shape_output=(batch_size, 3, int(dim_x / 2), int(dim_x / 2)),\n",
    "              num_epochs=100\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 1 took 79.137s\n",
      "  training loss (in-iteration): \t0.004873\n"
     ]
    }
   ],
   "source": [
    "train_group4_network(net16_group4, criterion, optimizer, mask_input_1, mask_output_3,\n",
    "#                      shape_input=(batch_size, 3, dim_x, dim_x),\n",
    "              shape_output=(batch_size, 3, int(dim_x / 2), int(dim_x / 2)),\n",
    "              num_epochs=1\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koloskov/anaconda3/lib/python3.6/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type Net16Group4. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(net16_group4, \"net16.group4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACxCAYAAADwMnaUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n41+YkHFpcQjEuwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2748111f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_batch_input = X_batch[:, 0].clone()\n",
    "X_batch_input[(~mask_input_3).nonzero()] = 0\n",
    "X_batch_input = Variable(X_batch_input).cuda()\n",
    "plot_gallery(X_batch_input.cpu().data, 8, 8, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_group_1 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(dim_x):\n",
    "            for j in range(dim_x):\n",
    "                if i % 2 == 0 and j % 2 == 0:\n",
    "                    mask_group_1[m][n][i][j] = True\n",
    "\n",
    "mask_group_2 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(dim_x):\n",
    "            for j in range(dim_x):\n",
    "                if i % 2 == 0 and j % 2 == 1:\n",
    "                    mask_group_2[m][n][i][j] = True\n",
    "\n",
    "mask_group_3 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(dim_x):\n",
    "            for j in range(dim_x):\n",
    "                if i % 2 == 1 and j % 2 == 0:\n",
    "                    mask_group_3[m][n][i][j] = True\n",
    "\n",
    "mask_group_4 = np.zeros((batch_size, 3, dim_x, dim_x)).astype(bool)\n",
    "for m in range(batch_size):\n",
    "    for n in range(3):\n",
    "        for i in range(dim_x):\n",
    "            for j in range(dim_x):\n",
    "                if i % 2 == 1 and j % 2 == 1:\n",
    "                    mask_group_4[m][n][i][j] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_input_into_image_16(X_batch):\n",
    "    X_batch_input = X_batch[:, 0].clone()\n",
    "    X_batch_input = X_batch_input[mask_input_1.nonzero()].view((batch_size, 3, int(dim_x / 2), int(dim_x / 2)))\n",
    "\n",
    "    y_batch_output = y_batch[:, 1].clone()\n",
    "    y_batch_output = y_batch_output[mask_input_1.nonzero()].view((batch_size, 3, int(dim_x / 2), int(dim_x / 2)))\n",
    "\n",
    "    X_batch_input = Variable(convert_input_into_image_8(X_batch_input, y_batch_output)).cuda()\n",
    "    \n",
    "    group_1 = X_batch_input.cpu().data\n",
    "    \n",
    "    group_2 = net16_group2(X_batch_input,\n",
    "                 keypoints=autoencoder_stickmans_16(Variable(y_batch[:, 1]).cuda())[1],\n",
    "                 embeddings=autoencoder_people_16(Variable(X_batch[:, 0]).cuda())[1]).cpu().data\n",
    "    \n",
    "    X_cur_input = torch.zeros((batch_size, 3, int(dim_x / 2), dim_x)).float()\n",
    "    X_cur_input[mask_first_part.nonzero()] = group_1.view(-1).float()\n",
    "    X_cur_input[mask_second_part.nonzero()] = group_2.view(-1).float()\n",
    "    group_3 = net16_group3(Variable(X_cur_input).cuda(),\n",
    "             keypoints=autoencoder_stickmans_16(Variable(y_batch[:, 1]).cuda())[1],\n",
    "             embeddings=autoencoder_people_16(Variable(X_batch[:, 0]).cuda())[1]).cpu().data\n",
    "    \n",
    "    X_cur_input = torch.zeros((batch_size, 3, dim_x, dim_x)).float()\n",
    "    X_cur_input[mask16_group_1.nonzero()] = group_1.view(-1).float()\n",
    "    X_cur_input[mask16_group_2.nonzero()] = group_2.view(-1).float()\n",
    "    X_cur_input[mask16_group_3.nonzero()] = group_3.view(-1).float()\n",
    "    \n",
    "    group_4 = net16_group4(Variable(X_cur_input).cuda(),\n",
    "                         keypoints=autoencoder_stickmans_16(Variable(y_batch[:, 1]).cuda())[1],\n",
    "                         embeddings=autoencoder_people_16(Variable(X_batch[:, 0]).cuda())[1]).cpu().data\n",
    "    \n",
    "    final_image = torch.zeros_like(X_batch[:, 1]).float()\n",
    "    final_image[mask16_group_1.nonzero()] = group_1.view(-1).float()\n",
    "    final_image[mask_output_1.nonzero()] = group_2.view(-1).float()\n",
    "    final_image[mask_output_2.nonzero()] = group_3.view(-1).float()\n",
    "    final_image[mask_output_3.nonzero()] = group_4.view(-1).float()\n",
    "    \n",
    "    plot_gallery(X_batch[:, 0], 8, 8, 1, 1)\n",
    "    plot_gallery(X_batch[:, 1], 8, 8, 1, 1)\n",
    "    plot_gallery(final_image, 8, 8, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, (X_batch, y_batch) in enumerate(val_loader):\n",
    "    if i == 18:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMUAAADFCAYAAADkODbwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff17c1fb7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMUAAADFCAYAAADkODbwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngENRAA5FATgUBeBQFIBDUQAORQE4/wJwWYZL/7gbcQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff175dfff60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMUAAADFCAYAAADkODbwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAFF1JREFUeJztndlvHHdyx7/dPSdnhsfwGl4iLcuy\nfMmWbdhBAsOysS+LHFjsv5enAHnaPMQIslgoUeRNvNZqsT7WG61PWRZJiRKHHM6QQ87d3Xnwwya/\n+v6AGa2ALODv57Fc6unpnmK7qqu+FaRpCiHEHwn/v09AiD83FBRCOCgohHBQUAjhoKAQwkFBIYSD\ngkIIBwWFEA4KCiEcMpM4V6vVdGNjw9ij0MaW7z15MLYRGI1ia/S9gQ/sQSZwRZomHl/73c7ap9Q3\nm7OXs3/GfU9PrX00GlHfyswMt1emjS3M5qhvktjvF5L75rMnyfidD6nn7mci9nn85iexvfdRxvdz\nZZ9nj7uzs4NGo+H5tf2RiYJiY2MD165dM/bS1JSxTRIUYcC9m8cn9riDPvVNQvtVkpR//0zG3pxh\n74z75ovG9psbv6K+tc0lY7v725vU9+bND4zt4PCA+r7747+l9rfeesfYKqvnqG+3b6/b1FSJ+hbz\nNrC6/SH1ZXd0OOK+1ZmKNUb8J9hpNo1tdsleXwBIYvvHJCTHffvtt+m/N/92LC8hfkAoKIRwUFAI\n4TBRThGGIYokf4hJRutLzAKSP/h8Y5JoxwE/5YhkMb68JiZJXIKI+rL/X107X6O+//QPf29sYcf+\nvzEArC7a5HljZZH63v7sU2rfWF81tqdn56lvLmuvW+q57q3WsbEVPfnHiOQP2Yhfy9OzjrHNVfn5\nlqpVYws8SXka8s97XPSkEMJBQSGEg4JCCAcFhRAOEyXaAJCSN6Psra/nZSlCEofDeEB96RtM8vkA\nfykY93rUt1Au28N6kriApOtxzM9ha2HW2BaK/IXTCy9fNrZr19+nvi9vrVB779EDY0sG/Dv3k6yx\nhTmePFembRFg6HnbHrAk1/POuECKNCxRB4CIJOu+roM0IZ0Pf0LyrSeFEA4KCiEcFBRCOCgohHBQ\nUAjhMHH1ic8t2KqAr8UiIZWJLGlBAIDTU1uZ8Ckahqy1wFOBGJD2kdGgS31H5Jv84eMPqe93u/eN\nLbfEZyEebX9nbM9vrlHfh40jau8Pbbv7wf171Hfr2eeMLZ+zFSkAGI5sNZC1YgNAQio/mQyf6ej3\nbPt6qcorYDE5buApadK7zIZmxkRPCiEcFBRCOCgohHBQUAjhMHmiTZJqlgAFnvloNtTOhvgBIJux\niWCvy2epc2RgfwhPCwFpSwk8LQRx37Y3XP3R31Hf5p0vja2Y4393KkTk4LM2b6V49fJL1N46emRs\n+SxPng/27TVeyNi2CwCoztniwFmHz8ZX5+aMrd1uU99C3p7bcMhbfJg4RHmazHiDt3nQwsuY6Ekh\nhIOCQggHBYUQDgoKIRwUFEI4PEabB4kjMvjjG9oJiblChn4A4PjEKgT6Xt8PSBVjOOTVp5Aco0ta\nEACulnfj5+9R34eNlrFtLj1NfRNy6d/cXKa+hx7lwKOW/bzu1C71ffkvLxgbG7YCgG5sK4RDz3BX\ni0mIelRCekNbJcoX+N/lMpEKjdiPB0DK5Dj/hAWnelII4aCgEMJBQSGEg4JCCIeJE22W5wZEBj/0\nqW6QA/SJTDzARSE8h0UQkCTOs8+AJdqeLg90zuycxcqmTVoBoEQ6LMJjPgtx89dWzn9+4zz1ffYZ\nLq/f6VrljtRTXDh4sGNsi1Ge+obkfpZKHtlMUuAIPXMarPhCd5CAJ9Ujzz1i8zyh1DyEeHIoKIRw\nUFAI4aCgEMJBQSGEw+RasuTteRqTiocv+yeVglyeV0H6fVv5CTzDIxFZ7tjr8wGWgHyJXIGfQzay\nVZBOhyt/7O7UjW1/52vqO0WuY9hsUN9PPibtLgBKM1a7dr7EtWTTgFSEmAYrgLBo2z96nipRJlcw\nttijO5uSql/Go+RCz8tjT4meB6tejSvwoSeFEA4KCiEcFBRCOCgohHCYKNFOkgS9rk0yWQuAT96S\nzWOM+nZrJsC3d8ZD3hKSxjbZYgtiAD7TcXLCk9xiZcHYmkc8mX33Jz81tk/+/WfUt31ik9HZ0iV+\nDjnbogEAtU3b/tFNbeILAEMUja1R3+PHPWfvZ7nCZy+Yykc26ymGkEw3IZtqAaBNZmlmZm1hAQBS\nssF2RAo9445Y6EkhhIOCQggHBYUQDgoKIRwUFEI4TFR9CsMQ+aKtYiQk+59EzSPM8IpJClvlCTwL\nQbKszaPH2zxYFaI4batMAG9heekVuwAFABpNq66Ry/GKyTC2LSGff/lL6luuzlP78ejQ2LJFXvkZ\nwl63mSyf2smXq8bGlqgAQJS3erS+BS9Dsmo5T/SCAWBmzp6DR8yDKqOwQbJx0ZNCCAcFhRAOCgoh\nHBQUQjhMPE/BooglVoFPdoMseOl75hPoW3mS1ANATHrqkxFvCYlydnbi2CNNWSGLQhr7dgsqAORI\n0lmd5u0RM2tWTnNhkbdzjDytLU+t2gT8KLWFEADIT9nWjeOzY+o717EtFpUal/TsDEiLToYvV4lJ\nS0fsuZ9sEYtvliYmCTy0tEWIJ4eCQggHBYUQDgoKIRwUFEI4TK7mQWwTtXkQNY8CWYwCAIMeqWx4\n3vVHRDc2iHgLAauWTS8sUd+EaKWuPv089WWqJF8dPqS+jSNb+alvb1PfQYWfW9SwVakg4pUqpLZd\npTDiw1KHD+3iF6aAAgCza5vGlvO0WERkuUrkaQmJ2XKggJ8Du/da2iLEE0RBIYSDgkIIBwWFEA4T\nq3n0ezY5m5oiPfWeNo+EJFAH9UfUN2KSir0z6ssSs9izpZMpSDzauUN9q/O2veHsyM5NAMA2kb0M\niOwmACBn2zHmnnudup4e8etz7vy6sd3d5e0q62TRzP0dnthPV2rGFg/5/ex1bQJPOkq+P8bA/naS\nIp+l6bZtq0l5Zpr60uU+j59n60khhIuCQggHBYUQDgoKIRwUFEI4TKzmwVoZ2KBIknpe9Qe2ijG/\nyJU0TlpNY0tJ1QYA2MdFZKAJAEIygLK8wdcAh6SxZdrTPrK8ZVsevv3vT6hv8WTf2Fr3vqC+/ewi\ntd/ftccI+MZg3P70t8Y2GvASTSWyQ1/f9rnvpZK9H3GFV5Qicu/YchUAKE7bSpNPn5hVGUNPm9E4\n6EkhhIOCQggHBYUQDgoKIRwmnqeISDtFQPrkM56kiDUL9Pu8rx8koc1EXL4xIIlV39MSAthEcP8B\nV+iora4aW/3+d9Q3l7f9DcMWb7tIs/YcFs5fpL4nTa66sbKxZmz7+/zzZhZtS8jgmB+X5dQL67b1\nAwByRVt4GXqKLMMzOx+Tz3DVDarc4ZnTYD+1mBRItLRFiMdEQSGEg4JCCAcFhRAOCgohHCauPiVM\nz2PE9EA9ah7ktX6hYCsYANDrnNqP8iwPCUlVLF/k0y7ZrFUPWd14ivqmRH2kdu489c3l7HGPHtyl\nvif7VuUjn3BN3ZMz3tqy+51V3egM+HWPB3ag6LDHVVQuLNlr+aWnXSUTt42ttmHbXQCguGxXHLNr\nBgAx+ZmltHbJW0VYNXLcPS56UgjhoKAQwkFBIYSDgkIIh4nVPHpdmwyWy3YxCVPMAICUZDtnRLnh\ne18bs0XSVgAA/a6Vt+ye8cQVRVsYaLa5QsdsZc4e94C3R5zm7Hejko4ASosrxlb/9B713bpiW00A\nYH7eFhJax0RqFMBrV98xti9ufkB9z0LbYvHSa3zeZPPFK8Z29OAe9Q16VtJz5PmdjAZ2MCRX4HMa\nIDM6UvMQ4gmioBDCQUEhhIOCQggHBYUQDhOreRSKtuVgNGISEp42D9ImMlXmK2b7jUNj6/Y91QpS\nbiiVeZtHRAZY5ma4QkeGDFCFM1Y7FwBKpDry7R/4AFV6aitjU8u8jaFxwKtzHbLat+2Zq4qv/dzY\nvt7n1/LCsm29+HjbtpQAQHPvgbEtL/A1yTFp0Vle4gtpMnl2Pzz6xGR6iA3DjYueFEI4KCiEcFBQ\nCOGgoBDCQUEhhMPEQ0Yh6V0KQnsYr5wI+Q9dsh0JAFJSwWKVBgDIkUGTbpdXbcLAnm/jgG8Lqm3Y\ngSLf4ND8sh2uKYOLuzbJAFSJz9tgZsb2SQFApmy/c7XNBr6AMG///r0y57mWgT3GUxc9g1WpvXcD\nz9/axWUrycP62wAAif1uIzLwBQARkclJPL7joCeFEA4KCiEcFBRCOCgohHCYXM3DswrYxbdgg7VY\nFD3DI71TqxQRMDURAIORPa8s0XYFgJAUBpbWuAJFSj5vrmZVKQCeNN6t84Gk2pxdRbz/0K4cBoAk\n4W0Tw0Pb09HxKHQUp+z1qbd4K87qvL1H9cNvqe90zh53dZ6rjzzcJmuSZ2eob0AUV0LPT48pxLBE\nfVz0pBDCQUEhhIOCQggHBYUQDgoKIRwmk7hJE/QHVqZkqmiHbgLPut6UVK92tu9R30LBHrdQ4pWY\nbtvqzs5Oz1LfRtNWefoDLoczVbAVrAf3+CajUt5WV5aX+RBNv2UleXqe77Ze4VW0jYvPGdud27wF\n5ZU3nze2L29/Q32nZ2w1MPFo+F548UVjOz7k25RWzlm93tAjAXS0t2NsC+tb1Hc0tK00UYYPjY2D\nnhRCOCgohHBQUAjhoKAQwmGiRDsIQrrwhOmBJiT5AXibx7nNLerbbNiE7eyEt02w5o+DI57wFfJW\nj9anaRpl7SVa8SwlYfq5t97/JfW9cOkFY5ut27YWAGiSIgIAND7+vbEdNfhsyv77N42tdciLC5cu\nzBtbJuXXZ++zW8Y2u2LXEwNAv2+LC2WP6Ov8ur3GvhYjllQH0pIV4smhoBDCQUEhhIOCQggHBYUQ\nDpNpyQYBsp7X8vbI3I9VaNh2JAAYDMmGmpirVbDiUZLYlhQAGBA1j6NdPkSTrNrWhFv/9s/Ud27R\nDh9trteob6tlB4ROsrw1oVbh7R+12oKxVaat/i4AzNYWjW1Qt2uLAWD9nK0+sRW8ANCs142tunmJ\n+g769j5nSSUQAGJSlSILlr73JSurw4j9/sYbPNKTQggHBYUQDgoKIRwUFEI4TJRop2lKZSvHVfgA\ngJBkS8UpvgTl9NS2Nwxj/ll50n4yHPDWhAJZCDK7tsV9ybm9/Bd2/S4ABKQV4sa//Cv1fYas2s3y\nugDOTrj8515i2yYO6rwl5P4jO58wV7brkAEgvmuLDktbz1Lfas1KerbJvAoAzC5YBZPh0CPzSZbl\nsLkJgLd5sOVAPiUY+2+FEP8HBYUQDgoKIRwUFEI4KCiEcJhMzSNJ0O10jL1UsmoTAVnuAgCjka3Q\n7O/xdoOUrIidqfD1wu1jO6BzQqpXABCQFoDIU0HrNpvG9nBvn/reIGt5X3/tder7m99/bmznsrY6\nAwDDJa4Pe/mybac4G3E1jwsrdmgnOuaqJJuvXjU2shcFANCFrfzML9o2EQBISfUom+OtLXHHDktF\nOV/rEGnzINVIeH6T5t+O5SXEDwgFhRAOCgohHBQUQjhMNk8RhigUrTQkU8LwvVCPiJzmQo3PHBzu\n24S2dcIVL5hMZ6nM5SbzJLlrdW0BAQAq09PGNpXhrQlvvmGT6q++vkN9N2tb9rhV+1kA0D7kbR47\nJOHf/mab+iZHdvvr8jxv85jZs8l6cf0i9S2za0mKEwBQILKio4FtVQEAkFYceKQ7WetQwAon3pW9\nzvHG8hLiB4SCQggHBYUQDgoKIRwUFEI4TLwymLVvhKTyw2wAXyXc7/LqypC0BWRI6wcA9Ae2IjTs\n8eMyZYr6Pd4e0S7ZismtG9ep7ydf2WO8c/Wvue/X1veNK5ep726Tf4950sYyu8RX8M5ubBnbm+e5\nkkYjsd95fppX8j7/yGrJPnPlDeobJ3xIiMGqlLGnFYfVlGJiHVdeVk8KIRwUFEI4KCiEcFBQCOEw\ncaLNtpvGKUuAeO96xNQ8PFtBg8aRsY3AG/szGRvfUYknncWCTTCr63zRSEhaC55/yS5cAYDmyJ5b\nvc1bHqK+nRf44NPfUd/yiCeYH7ZtAt4+4LKZc1esfSdjJUEBYHHLzmk0my3q+8xrf2VsJ8fct0zk\nP2NP9htS1Rje5pFhS1uI7OZ40xR6UghhUFAI4aCgEMJBQSGEg4JCCIcJtWQTjAa2apIvWr3VwcCj\n+5mzKgt1jzrGaGSPUSry1oSTY9vyEOULHl9btakUuJ7trRu/MLZf/Ooj6psZ2qUka1W7WAUAfndq\nfd958VXqe/2//oPa33rdKnTsxnYZDACEi2vGdulV/nn7pKuEVeEAoH9iK02pZ71wLiItQp62nb17\nVs+2RlpVvv9AstyHtCOpzUOIx0RBIYSDgkIIBwWFEA4TJdpBECLK2kSXbTyNIt6OwRZvVOe5zGK/\nb5UeWm2u5hERXcfRgCt0ZLNknqK+R32XFmyryNUXtqjvR9/sGttRypsLBie27eIf3/sZ9eWTDMB7\n128YW4a23AAbM/YoX6zyNphFsqDl7PiY+k6vbhlbp3FAfQslK3k65fm7vLJ53tjYFlQACMkmXnZU\ntXkI8ZgoKIRwUFAI4aCgEMJBQSGEw8RDRiGpKlGFj4DHG1vb2vFUNrJkbWwm4FWtkL3DJ20iAFCs\n2KpLt8tbEx7cty0ov75tWxAAoN+xLRZf3eELafqBPeGZIh+2Go1sSwgADFu2xWJhbZH67oe23WRu\nzbaJAECjbat22YxV+ACAR7u24laZ4xq1SG31iK1ZBoAk8WyJYZDf3yT6xi56UgjhoKAQwkFBIYSD\ngkIIh8nVPGgCQ1IYotoBAAlRWcgSdQ0AOKvbRLlH2kQAIEte9ScR3yp6eGgXmOQyPOErpH1jW5nn\n7RH7RBby3R9xCcnr//mhsTVPuQpG4GkV6ZMEc++Az1P8zaZNtHfrXI7zwsULxvZgmy+DWVhZtcd9\nwFtmzpdt68aQX3bkM/Z3MokU69hZNUFPCiEcFBRCOCgohHBQUAjhoKAQwiGgmbvPOQgOAPAyhBB/\n/mymacr7YP4XEwWFED8E9L9PQjgoKIRwUFAI4aCgEMJBQSGEg4JCCAcFhRAOCgohHBQUQjj8D8/V\n7CK8/pEeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff175db9ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "convert_input_into_image_16(X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMUAAADFCAYAAADkODbwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQwtHGKYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff1756ffef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_gallery(y_batch[:, 1], 8, 8, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, (X_batch, y_batch) in enumerate(train_loader):\n",
    "    if i == 15:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACxCAYAAADwMnaUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3ad85e1470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_gallery(X_batch[:, 0], 8, 8, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACxCAYAAADwMnaUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f27481113c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_gallery(net4_group4(X_batch_input,\n",
    "                 keypoints=autoencoder_stickmans(Variable(y_batch[:, 1]).cuda())[1],\n",
    "                 embeddings=autoencoder_people(Variable(X_batch[:, 0]).cuda())[1]).cpu().data,\n",
    "             8, 8, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACxCAYAAADwMnaUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f273e2dd668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_batch_output = X_batch[:, 1]\n",
    "X_batch_output = X_batch_output[mask_output.nonzero()].view((batch_size, 3, int(dim_x / 2), int(dim_x / 2)))\n",
    "plot_gallery(X_batch_output, 8, 8, 1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-187-b85b89fe8024>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mdancing_poses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mdummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_dance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mdummy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "initial_dance = np.array([ [138.,  27.],\n",
    "                           [133.,  53.],\n",
    "                           [114.,  50.],\n",
    "                           [108.,  90.],\n",
    "                           [114., 121.],\n",
    "                           [152.,  57.],\n",
    "                           [152.,  95.],\n",
    "                           [165., 126.],\n",
    "                           [118., 118.],\n",
    "                           [121., 172.],\n",
    "                           [144., 226.],\n",
    "                           [141., 118.],\n",
    "                           [140., 172.],\n",
    "                           [135., 225.],\n",
    "                           [135.,  21.],\n",
    "                           [144.,  23.],\n",
    "                           [129.,  22.],\n",
    "                           [150.,  27.] ]\n",
    "                        )\n",
    "\n",
    "def generate_circle_trajectory(radius, center, start_y, end_y):\n",
    "    y = np.arange(int(np.min([start_y, end_y])), int(np.max([start_y, end_y])) + 1)\n",
    "    \n",
    "    x = np.round(center[0] + np.sqrt(radius ** 2 - (y - center[1]) ** 2)).astype(np.int32)\n",
    "    return x\n",
    "\n",
    "dancing_poses = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    dummy = np.copy(initial_dance)\n",
    "    dummy[7] = dummy[6] - np.array([-x[i], y[i]])\n",
    "    dummy[4] = dummy[3] - np.array([x[i], y[i]])\n",
    "    #plt.imshow(dataset.make_joint_img((256, 256, 3), dataset.jo, dummy))\n",
    "    #plt.show()\n",
    "    dancing_poses.append(dummy)\n",
    "\n",
    "for i in range(len(x)):\n",
    "    dummy = np.copy(initial_dance)\n",
    "    dummy[7] = dummy[6] + np.array([x[i], y[i]])\n",
    "    dummy[4] = dummy[3] + np.array([-x[i], y[i]])\n",
    "    #plt.imshow(dataset.make_joint_img((256, 256, 3), dataset.jo, dummy))\n",
    "    #plt.show()\n",
    "    dancing_poses.append(dummy)\n",
    "    \n",
    "np.save('dancing_poses.npy', np.array(dancing_poses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
